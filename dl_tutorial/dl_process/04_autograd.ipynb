{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.551916900Z",
     "start_time": "2023-05-29T06:27:09.028523400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# 梯度的必須是32位或是64位的浮点数，且必须是 n 维矩阵形式，例子中的 2.0 会自动转换乘 [2.0]\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "y = w * 3\n",
    "\n",
    "# w 的梯度值(即為∂y/∂w)\n",
    "print(w.grad)\n",
    "y.backward()\n",
    "print(w.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.612615400Z",
     "start_time": "2023-05-29T06:27:12.553918Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "# 梯度的必須是32位或是64位的浮点数，且必须是 n 维矩阵形式，例子中的 2.0 会自动转换乘 [2.0]\n",
    "w = torch.tensor(2.0, requires_grad=True)\n",
    "y = w * 3\n",
    "\n",
    "# w 的梯度值(即為∂y/∂w)\n",
    "print(w.grad)\n",
    "y.backward()\n",
    "print(w.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.628614600Z",
     "start_time": "2023-05-29T06:27:12.614615400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True])\n",
      "tensor([True, True])\n",
      "tensor([36., 81.])\n",
      "tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3 * a ** 3 - b ** 2  # 假设 a 和 b 是 NN 的参数，Q 是 loss\n",
    "\n",
    "# ∂Q/∂a = 9a^2\n",
    "# ∂Q/∂b = -2b\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)  # 需要显式地传入 gradient， 它与 Q 的形状(shape)相同\n",
    "# ∂Q/∂Q = 1\n",
    "\n",
    "print(9 * a ** 2 == a.grad)\n",
    "print(-2 * b == b.grad)\n",
    "print(a.grad)\n",
    "print(b.grad)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.688614700Z",
     "start_time": "2023-05-29T06:27:12.631614700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.709132500Z",
     "start_time": "2023-05-29T06:27:12.643614700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n",
      "tensor([True, True])\n",
      "tensor([True, True])\n",
      "tensor([36., 81.])\n",
      "tensor([-12.,  -8.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = x ** 2 + 2\n",
    "z = torch.sum(y)\n",
    "print(z)\n",
    "z.backward()\n",
    "print(x.grad)  #%%\n",
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)\n",
    "\n",
    "Q = 3 * a ** 3 - b ** 2  # 假设 a 和 b 是 NN 的参数，Q 是 loss\n",
    "\n",
    "# ∂Q/∂a = 9a^2\n",
    "# ∂Q/∂b = -2b\n",
    "\n",
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)  # 需要显式地传入 gradient， 它与 Q 的形状(shape)相同\n",
    "# ∂Q/∂Q = 1\n",
    "\n",
    "print(9 * a ** 2 == a.grad)\n",
    "print(-2 * b == b.grad)\n",
    "print(a.grad)\n",
    "print(b.grad)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.710131400Z",
     "start_time": "2023-05-29T06:27:12.663615600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does `a` require gradients? : False\n",
      "Does `b` require gradients?: True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 5)\n",
    "y = torch.rand(5, 5)\n",
    "z = torch.rand((5, 5), requires_grad=True)\n",
    "\n",
    "a = x + y\n",
    "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
    "b = x + z\n",
    "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.710131400Z",
     "start_time": "2023-05-29T06:27:12.676615Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20., grad_fn=<SumBackward0>)\n",
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)\n",
    "y = x ** 2 + 2\n",
    "z = torch.sum(y)\n",
    "print(z)\n",
    "z.backward()\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-29T06:27:12.711131800Z",
     "start_time": "2023-05-29T06:27:12.693620200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
