{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "训练模型是个迭代过程，在每个迭代（也称之为 `epoch`）中，该模型对输出进行猜测，计算其猜测中的误差（损失），收集误差相对于其参数的导数（如我们在前面的模块中看到的），并使用梯度下降优化这些参数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.477002700Z",
     "start_time": "2023-08-23T09:21:51.679629800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.570004400Z",
     "start_time": "2023-08-23T09:21:55.480004200Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "`超参` 指的是那些在训练过程中明确设置的参数。这些参数用于控制训练过程本身的行为，而不是模型内部的参数值。我们在本文中设置的超参数如下：\n",
    "- `Epoch` 的数量——训练数据集上迭代的次数。\n",
    "- `Batch size`——每次迭代中传递给模型的数据样本数量。\n",
    "- `Learning rate`——优化器内部使用的更新模型参数的大小。较大的值可能会导致收敛过程中的振荡，较小的值可能会导致收敛速度过慢。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.585002300Z",
     "start_time": "2023-08-23T09:21:55.571003400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "损失函数的作用：\n",
    "- 损失函数衡量得到的结果与目标值的不同程度\n",
    "- 损失函数的梯度有助于优化器在训练期间进行适当的参数调整\n",
    "- 损失函数是在训练过程中以最小化为目标"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.603003400Z",
     "start_time": "2023-08-23T09:21:55.587001800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.619002900Z",
     "start_time": "2023-08-23T09:21:55.602003Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "在迭代训练中，通常由三步构成：\n",
    "- 调用 `optimizer.zero_grad()` 重置模型参数的梯度。默认情况下，每次调用 `.backward()` ，梯度都会累积（即不会被重写）。\n",
    "- 调用 `loss.backward()` 计算当前迭代的损失相对于模型参数的梯度。\n",
    "- 调用 `optimizer.step()` 更新内部参数。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100 * correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:21:55.635001900Z",
     "start_time": "2023-08-23T09:21:55.618002800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306314  [    0/60000]\n",
      "loss: 2.294907  [ 6400/60000]\n",
      "loss: 2.288003  [12800/60000]\n",
      "loss: 2.288475  [19200/60000]\n",
      "loss: 2.258991  [25600/60000]\n",
      "loss: 2.252877  [32000/60000]\n",
      "loss: 2.260994  [38400/60000]\n",
      "loss: 2.244441  [44800/60000]\n",
      "loss: 2.239319  [51200/60000]\n",
      "loss: 2.205755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 35.6%, Avg loss: 0.034928 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.224386  [    0/60000]\n",
      "loss: 2.210661  [ 6400/60000]\n",
      "loss: 2.199962  [12800/60000]\n",
      "loss: 2.226555  [19200/60000]\n",
      "loss: 2.155198  [25600/60000]\n",
      "loss: 2.137745  [32000/60000]\n",
      "loss: 2.167524  [38400/60000]\n",
      "loss: 2.131406  [44800/60000]\n",
      "loss: 2.128834  [51200/60000]\n",
      "loss: 2.073429  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 0.033206 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.100661  [    0/60000]\n",
      "loss: 2.080134  [ 6400/60000]\n",
      "loss: 2.063914  [12800/60000]\n",
      "loss: 2.135560  [19200/60000]\n",
      "loss: 2.002897  [25600/60000]\n",
      "loss: 1.975248  [32000/60000]\n",
      "loss: 2.035353  [38400/60000]\n",
      "loss: 1.977477  [44800/60000]\n",
      "loss: 1.988769  [51200/60000]\n",
      "loss: 1.899398  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 42.3%, Avg loss: 0.031066 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.944336  [    0/60000]\n",
      "loss: 1.919783  [ 6400/60000]\n",
      "loss: 1.896523  [12800/60000]\n",
      "loss: 2.005754  [19200/60000]\n",
      "loss: 1.833724  [25600/60000]\n",
      "loss: 1.814720  [32000/60000]\n",
      "loss: 1.878460  [38400/60000]\n",
      "loss: 1.830412  [44800/60000]\n",
      "loss: 1.846402  [51200/60000]\n",
      "loss: 1.722606  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.7%, Avg loss: 0.028300 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.788427  [    0/60000]\n",
      "loss: 1.712050  [ 6400/60000]\n",
      "loss: 1.689438  [12800/60000]\n",
      "loss: 1.835489  [19200/60000]\n",
      "loss: 1.637493  [25600/60000]\n",
      "loss: 1.666788  [32000/60000]\n",
      "loss: 1.717074  [38400/60000]\n",
      "loss: 1.694237  [44800/60000]\n",
      "loss: 1.680527  [51200/60000]\n",
      "loss: 1.568292  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.8%, Avg loss: 0.025751 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.622089  [    0/60000]\n",
      "loss: 1.529340  [ 6400/60000]\n",
      "loss: 1.504958  [12800/60000]\n",
      "loss: 1.693208  [19200/60000]\n",
      "loss: 1.468095  [25600/60000]\n",
      "loss: 1.547452  [32000/60000]\n",
      "loss: 1.591934  [38400/60000]\n",
      "loss: 1.596252  [44800/60000]\n",
      "loss: 1.550173  [51200/60000]\n",
      "loss: 1.458593  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 53.3%, Avg loss: 0.023835 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.494557  [    0/60000]\n",
      "loss: 1.398065  [ 6400/60000]\n",
      "loss: 1.369548  [12800/60000]\n",
      "loss: 1.588542  [19200/60000]\n",
      "loss: 1.345709  [25600/60000]\n",
      "loss: 1.460259  [32000/60000]\n",
      "loss: 1.505369  [38400/60000]\n",
      "loss: 1.527648  [44800/60000]\n",
      "loss: 1.458329  [51200/60000]\n",
      "loss: 1.382254  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 0.022456 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.401790  [    0/60000]\n",
      "loss: 1.307252  [ 6400/60000]\n",
      "loss: 1.272988  [12800/60000]\n",
      "loss: 1.510102  [19200/60000]\n",
      "loss: 1.263236  [25600/60000]\n",
      "loss: 1.394916  [32000/60000]\n",
      "loss: 1.444833  [38400/60000]\n",
      "loss: 1.475770  [44800/60000]\n",
      "loss: 1.391340  [51200/60000]\n",
      "loss: 1.327171  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 54.8%, Avg loss: 0.021429 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.331065  [    0/60000]\n",
      "loss: 1.241747  [ 6400/60000]\n",
      "loss: 1.200217  [12800/60000]\n",
      "loss: 1.448934  [19200/60000]\n",
      "loss: 1.204905  [25600/60000]\n",
      "loss: 1.342535  [32000/60000]\n",
      "loss: 1.393365  [38400/60000]\n",
      "loss: 1.326697  [44800/60000]\n",
      "loss: 1.252646  [51200/60000]\n",
      "loss: 1.192560  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 56.7%, Avg loss: 0.018977 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.135166  [    0/60000]\n",
      "loss: 1.136540  [ 6400/60000]\n",
      "loss: 1.019779  [12800/60000]\n",
      "loss: 1.336094  [19200/60000]\n",
      "loss: 1.108759  [25600/60000]\n",
      "loss: 1.081093  [32000/60000]\n",
      "loss: 1.217544  [38400/60000]\n",
      "loss: 1.157406  [44800/60000]\n",
      "loss: 1.166013  [51200/60000]\n",
      "loss: 1.130868  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.9%, Avg loss: 0.017746 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:23:08.338314900Z",
     "start_time": "2023-08-23T09:21:55.634002600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"./data/model.pt\")\n",
    "\n",
    "print(\"Saved PyTorch Model State to model.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-23T09:23:08.383313800Z",
     "start_time": "2023-08-23T09:23:08.340317Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
