{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-19T08:01:52.666215200Z",
     "start_time": "2023-05-19T08:01:52.655216100Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = './samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 784\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T08:01:52.685212600Z",
     "start_time": "2023-05-19T08:01:52.667216100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                     train=True,\n",
    "                                     transform=transforms.ToTensor(),\n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T08:01:52.727771400Z",
     "start_time": "2023-05-19T08:01:52.682215500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# VAE model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return F.sigmoid(self.fc5(h))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T08:01:52.744771400Z",
     "start_time": "2023-05-19T08:01:52.732768800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ping\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/469], Reconst Loss: 35242.7734, KL Div: 3123.7285\n",
      "Epoch[1/15], Step [20/469], Reconst Loss: 29813.1973, KL Div: 1044.8146\n",
      "Epoch[1/15], Step [30/469], Reconst Loss: 27558.4648, KL Div: 1083.4075\n",
      "Epoch[1/15], Step [40/469], Reconst Loss: 26327.8711, KL Div: 769.2410\n",
      "Epoch[1/15], Step [50/469], Reconst Loss: 26661.4922, KL Div: 646.4868\n",
      "Epoch[1/15], Step [60/469], Reconst Loss: 24742.1094, KL Div: 901.4807\n",
      "Epoch[1/15], Step [70/469], Reconst Loss: 25270.2109, KL Div: 888.2271\n",
      "Epoch[1/15], Step [80/469], Reconst Loss: 23387.4570, KL Div: 1035.5004\n",
      "Epoch[1/15], Step [90/469], Reconst Loss: 23328.0156, KL Div: 1317.0667\n",
      "Epoch[1/15], Step [100/469], Reconst Loss: 21932.7910, KL Div: 1375.3115\n",
      "Epoch[1/15], Step [110/469], Reconst Loss: 20771.7383, KL Div: 1496.0787\n",
      "Epoch[1/15], Step [120/469], Reconst Loss: 20733.5098, KL Div: 1631.4050\n",
      "Epoch[1/15], Step [130/469], Reconst Loss: 19440.8418, KL Div: 1685.2507\n",
      "Epoch[1/15], Step [140/469], Reconst Loss: 19241.5547, KL Div: 1898.3066\n",
      "Epoch[1/15], Step [150/469], Reconst Loss: 19057.1172, KL Div: 1844.1337\n",
      "Epoch[1/15], Step [160/469], Reconst Loss: 19078.3164, KL Div: 1718.7043\n",
      "Epoch[1/15], Step [170/469], Reconst Loss: 18059.5078, KL Div: 1849.8765\n",
      "Epoch[1/15], Step [180/469], Reconst Loss: 18018.3281, KL Div: 1829.2646\n",
      "Epoch[1/15], Step [190/469], Reconst Loss: 17186.4590, KL Div: 1915.3494\n",
      "Epoch[1/15], Step [200/469], Reconst Loss: 16905.2793, KL Div: 1985.4471\n",
      "Epoch[1/15], Step [210/469], Reconst Loss: 17643.2480, KL Div: 2044.9011\n",
      "Epoch[1/15], Step [220/469], Reconst Loss: 17307.8633, KL Div: 1993.7048\n",
      "Epoch[1/15], Step [230/469], Reconst Loss: 16389.6523, KL Div: 2130.7786\n",
      "Epoch[1/15], Step [240/469], Reconst Loss: 16694.1562, KL Div: 2064.3977\n",
      "Epoch[1/15], Step [250/469], Reconst Loss: 16515.6211, KL Div: 2235.9585\n",
      "Epoch[1/15], Step [260/469], Reconst Loss: 16523.0527, KL Div: 2275.3013\n",
      "Epoch[1/15], Step [270/469], Reconst Loss: 15511.8613, KL Div: 2290.3601\n",
      "Epoch[1/15], Step [280/469], Reconst Loss: 15885.8945, KL Div: 2263.4512\n",
      "Epoch[1/15], Step [290/469], Reconst Loss: 16302.6201, KL Div: 2252.7622\n",
      "Epoch[1/15], Step [300/469], Reconst Loss: 15572.1973, KL Div: 2355.1628\n",
      "Epoch[1/15], Step [310/469], Reconst Loss: 14667.7988, KL Div: 2350.1985\n",
      "Epoch[1/15], Step [320/469], Reconst Loss: 15554.9072, KL Div: 2347.3149\n",
      "Epoch[1/15], Step [330/469], Reconst Loss: 15210.0928, KL Div: 2551.0193\n",
      "Epoch[1/15], Step [340/469], Reconst Loss: 14981.8672, KL Div: 2373.9270\n",
      "Epoch[1/15], Step [350/469], Reconst Loss: 15389.7715, KL Div: 2471.9641\n",
      "Epoch[1/15], Step [360/469], Reconst Loss: 15073.0850, KL Div: 2476.4426\n",
      "Epoch[1/15], Step [370/469], Reconst Loss: 14569.4404, KL Div: 2531.4875\n",
      "Epoch[1/15], Step [380/469], Reconst Loss: 14032.2520, KL Div: 2345.0793\n",
      "Epoch[1/15], Step [390/469], Reconst Loss: 14740.4600, KL Div: 2664.4277\n",
      "Epoch[1/15], Step [400/469], Reconst Loss: 14635.5273, KL Div: 2622.3262\n",
      "Epoch[1/15], Step [410/469], Reconst Loss: 14671.1973, KL Div: 2612.3013\n",
      "Epoch[1/15], Step [420/469], Reconst Loss: 14374.0762, KL Div: 2556.2051\n",
      "Epoch[1/15], Step [430/469], Reconst Loss: 13410.5078, KL Div: 2553.5869\n",
      "Epoch[1/15], Step [440/469], Reconst Loss: 13839.3975, KL Div: 2538.3955\n",
      "Epoch[1/15], Step [450/469], Reconst Loss: 14398.0068, KL Div: 2499.7891\n",
      "Epoch[1/15], Step [460/469], Reconst Loss: 14091.9180, KL Div: 2538.1538\n",
      "Epoch[2/15], Step [10/469], Reconst Loss: 13593.4990, KL Div: 2687.2153\n",
      "Epoch[2/15], Step [20/469], Reconst Loss: 12843.1758, KL Div: 2503.7983\n",
      "Epoch[2/15], Step [30/469], Reconst Loss: 13938.2598, KL Div: 2612.4316\n",
      "Epoch[2/15], Step [40/469], Reconst Loss: 13950.3760, KL Div: 2713.8196\n",
      "Epoch[2/15], Step [50/469], Reconst Loss: 13016.4180, KL Div: 2580.8682\n",
      "Epoch[2/15], Step [60/469], Reconst Loss: 13264.0186, KL Div: 2668.0164\n",
      "Epoch[2/15], Step [70/469], Reconst Loss: 13103.9600, KL Div: 2619.5789\n",
      "Epoch[2/15], Step [80/469], Reconst Loss: 13190.2832, KL Div: 2706.6038\n",
      "Epoch[2/15], Step [90/469], Reconst Loss: 13038.2432, KL Div: 2739.0786\n",
      "Epoch[2/15], Step [100/469], Reconst Loss: 13089.7266, KL Div: 2871.4805\n",
      "Epoch[2/15], Step [110/469], Reconst Loss: 13184.7656, KL Div: 2723.7163\n",
      "Epoch[2/15], Step [120/469], Reconst Loss: 11984.2305, KL Div: 2719.9375\n",
      "Epoch[2/15], Step [130/469], Reconst Loss: 13141.7559, KL Div: 2656.0557\n",
      "Epoch[2/15], Step [140/469], Reconst Loss: 13588.4453, KL Div: 2771.0344\n",
      "Epoch[2/15], Step [150/469], Reconst Loss: 13652.2031, KL Div: 2849.6924\n",
      "Epoch[2/15], Step [160/469], Reconst Loss: 12713.5059, KL Div: 2774.9368\n",
      "Epoch[2/15], Step [170/469], Reconst Loss: 12735.6504, KL Div: 2741.7781\n",
      "Epoch[2/15], Step [180/469], Reconst Loss: 12731.1074, KL Div: 2836.3813\n",
      "Epoch[2/15], Step [190/469], Reconst Loss: 12705.2871, KL Div: 2682.4187\n",
      "Epoch[2/15], Step [200/469], Reconst Loss: 12787.9170, KL Div: 2929.0537\n",
      "Epoch[2/15], Step [210/469], Reconst Loss: 12609.7910, KL Div: 2677.2676\n",
      "Epoch[2/15], Step [220/469], Reconst Loss: 12420.4209, KL Div: 2712.4639\n",
      "Epoch[2/15], Step [230/469], Reconst Loss: 12094.8359, KL Div: 2664.8887\n",
      "Epoch[2/15], Step [240/469], Reconst Loss: 12387.1699, KL Div: 2837.6763\n",
      "Epoch[2/15], Step [250/469], Reconst Loss: 12745.6484, KL Div: 2889.8223\n",
      "Epoch[2/15], Step [260/469], Reconst Loss: 12831.3809, KL Div: 2816.4839\n",
      "Epoch[2/15], Step [270/469], Reconst Loss: 12196.2568, KL Div: 2842.6211\n",
      "Epoch[2/15], Step [280/469], Reconst Loss: 12975.8555, KL Div: 2853.0503\n",
      "Epoch[2/15], Step [290/469], Reconst Loss: 12363.8828, KL Div: 2846.9106\n",
      "Epoch[2/15], Step [300/469], Reconst Loss: 12068.6807, KL Div: 2795.0249\n",
      "Epoch[2/15], Step [310/469], Reconst Loss: 12371.1006, KL Div: 2934.8706\n",
      "Epoch[2/15], Step [320/469], Reconst Loss: 12239.4521, KL Div: 2883.2363\n",
      "Epoch[2/15], Step [330/469], Reconst Loss: 12938.6396, KL Div: 2749.1792\n",
      "Epoch[2/15], Step [340/469], Reconst Loss: 12783.8008, KL Div: 2882.9924\n",
      "Epoch[2/15], Step [350/469], Reconst Loss: 13005.2363, KL Div: 2743.1484\n",
      "Epoch[2/15], Step [360/469], Reconst Loss: 12182.3652, KL Div: 2873.6899\n",
      "Epoch[2/15], Step [370/469], Reconst Loss: 12707.2871, KL Div: 2911.8872\n",
      "Epoch[2/15], Step [380/469], Reconst Loss: 12245.8955, KL Div: 2880.5981\n",
      "Epoch[2/15], Step [390/469], Reconst Loss: 12613.2598, KL Div: 2921.3069\n",
      "Epoch[2/15], Step [400/469], Reconst Loss: 12112.4238, KL Div: 2904.1768\n",
      "Epoch[2/15], Step [410/469], Reconst Loss: 11994.2432, KL Div: 2923.8828\n",
      "Epoch[2/15], Step [420/469], Reconst Loss: 11943.7861, KL Div: 2878.6938\n",
      "Epoch[2/15], Step [430/469], Reconst Loss: 11929.7129, KL Div: 2880.7563\n",
      "Epoch[2/15], Step [440/469], Reconst Loss: 12092.4980, KL Div: 2912.0757\n",
      "Epoch[2/15], Step [450/469], Reconst Loss: 12552.1074, KL Div: 2887.7468\n",
      "Epoch[2/15], Step [460/469], Reconst Loss: 11791.5078, KL Div: 2896.1345\n",
      "Epoch[3/15], Step [10/469], Reconst Loss: 12033.7148, KL Div: 3004.1443\n",
      "Epoch[3/15], Step [20/469], Reconst Loss: 12847.9434, KL Div: 2980.3193\n",
      "Epoch[3/15], Step [30/469], Reconst Loss: 11643.7334, KL Div: 2924.4614\n",
      "Epoch[3/15], Step [40/469], Reconst Loss: 11762.0195, KL Div: 3068.2686\n",
      "Epoch[3/15], Step [50/469], Reconst Loss: 12169.3945, KL Div: 2820.3469\n",
      "Epoch[3/15], Step [60/469], Reconst Loss: 11357.0898, KL Div: 3057.6436\n",
      "Epoch[3/15], Step [70/469], Reconst Loss: 11638.1885, KL Div: 2919.2222\n",
      "Epoch[3/15], Step [80/469], Reconst Loss: 11301.7334, KL Div: 2914.9089\n",
      "Epoch[3/15], Step [90/469], Reconst Loss: 12154.7422, KL Div: 2909.6980\n",
      "Epoch[3/15], Step [100/469], Reconst Loss: 11768.9570, KL Div: 2974.0811\n",
      "Epoch[3/15], Step [110/469], Reconst Loss: 12420.1875, KL Div: 3056.4583\n",
      "Epoch[3/15], Step [120/469], Reconst Loss: 11694.8076, KL Div: 2899.2319\n",
      "Epoch[3/15], Step [130/469], Reconst Loss: 11768.0410, KL Div: 2986.2163\n",
      "Epoch[3/15], Step [140/469], Reconst Loss: 11854.6875, KL Div: 3079.8604\n",
      "Epoch[3/15], Step [150/469], Reconst Loss: 11844.2734, KL Div: 2941.4355\n",
      "Epoch[3/15], Step [160/469], Reconst Loss: 11164.4834, KL Div: 2935.5146\n",
      "Epoch[3/15], Step [170/469], Reconst Loss: 11850.7910, KL Div: 2990.8562\n",
      "Epoch[3/15], Step [180/469], Reconst Loss: 11268.4844, KL Div: 3004.4819\n",
      "Epoch[3/15], Step [190/469], Reconst Loss: 11980.1133, KL Div: 2916.4319\n",
      "Epoch[3/15], Step [200/469], Reconst Loss: 11442.8750, KL Div: 2978.3765\n",
      "Epoch[3/15], Step [210/469], Reconst Loss: 11799.7598, KL Div: 3047.9133\n",
      "Epoch[3/15], Step [220/469], Reconst Loss: 11868.0117, KL Div: 2881.6968\n",
      "Epoch[3/15], Step [230/469], Reconst Loss: 11998.9082, KL Div: 3071.8630\n",
      "Epoch[3/15], Step [240/469], Reconst Loss: 11943.1641, KL Div: 3102.1357\n",
      "Epoch[3/15], Step [250/469], Reconst Loss: 11554.1689, KL Div: 2966.1963\n",
      "Epoch[3/15], Step [260/469], Reconst Loss: 12030.3428, KL Div: 3006.2168\n",
      "Epoch[3/15], Step [270/469], Reconst Loss: 11279.0518, KL Div: 3061.8652\n",
      "Epoch[3/15], Step [280/469], Reconst Loss: 11985.3652, KL Div: 2988.3887\n",
      "Epoch[3/15], Step [290/469], Reconst Loss: 11314.0625, KL Div: 3008.8779\n",
      "Epoch[3/15], Step [300/469], Reconst Loss: 11466.6553, KL Div: 3044.8589\n",
      "Epoch[3/15], Step [310/469], Reconst Loss: 11913.8467, KL Div: 3017.1265\n",
      "Epoch[3/15], Step [320/469], Reconst Loss: 11560.4727, KL Div: 3037.3721\n",
      "Epoch[3/15], Step [330/469], Reconst Loss: 11517.0762, KL Div: 3006.4866\n",
      "Epoch[3/15], Step [340/469], Reconst Loss: 11579.8359, KL Div: 2962.9644\n",
      "Epoch[3/15], Step [350/469], Reconst Loss: 11491.0703, KL Div: 3190.3052\n",
      "Epoch[3/15], Step [360/469], Reconst Loss: 11215.8369, KL Div: 2964.8423\n",
      "Epoch[3/15], Step [370/469], Reconst Loss: 11762.0938, KL Div: 3163.7522\n",
      "Epoch[3/15], Step [380/469], Reconst Loss: 11302.8125, KL Div: 2917.6396\n",
      "Epoch[3/15], Step [390/469], Reconst Loss: 11813.8838, KL Div: 2997.0476\n",
      "Epoch[3/15], Step [400/469], Reconst Loss: 11670.4561, KL Div: 2989.8906\n",
      "Epoch[3/15], Step [410/469], Reconst Loss: 11871.0264, KL Div: 3019.6597\n",
      "Epoch[3/15], Step [420/469], Reconst Loss: 11257.0430, KL Div: 3099.2046\n",
      "Epoch[3/15], Step [430/469], Reconst Loss: 11799.2979, KL Div: 3089.1265\n",
      "Epoch[3/15], Step [440/469], Reconst Loss: 11563.7812, KL Div: 3079.4966\n",
      "Epoch[3/15], Step [450/469], Reconst Loss: 11490.4990, KL Div: 3072.2695\n",
      "Epoch[3/15], Step [460/469], Reconst Loss: 10980.9785, KL Div: 3050.3926\n",
      "Epoch[4/15], Step [10/469], Reconst Loss: 11717.4727, KL Div: 3020.0054\n",
      "Epoch[4/15], Step [20/469], Reconst Loss: 11318.1533, KL Div: 3116.4512\n",
      "Epoch[4/15], Step [30/469], Reconst Loss: 10915.9805, KL Div: 3038.4290\n",
      "Epoch[4/15], Step [40/469], Reconst Loss: 11266.9131, KL Div: 3105.6897\n",
      "Epoch[4/15], Step [50/469], Reconst Loss: 11426.5674, KL Div: 3041.4712\n",
      "Epoch[4/15], Step [60/469], Reconst Loss: 11578.2129, KL Div: 3133.3589\n",
      "Epoch[4/15], Step [70/469], Reconst Loss: 11141.0010, KL Div: 3003.6860\n",
      "Epoch[4/15], Step [80/469], Reconst Loss: 11628.6963, KL Div: 3037.1868\n",
      "Epoch[4/15], Step [90/469], Reconst Loss: 11550.6826, KL Div: 3231.0654\n",
      "Epoch[4/15], Step [100/469], Reconst Loss: 11388.2354, KL Div: 3156.0591\n",
      "Epoch[4/15], Step [110/469], Reconst Loss: 10970.6367, KL Div: 2995.5742\n",
      "Epoch[4/15], Step [120/469], Reconst Loss: 11476.2070, KL Div: 3151.9802\n",
      "Epoch[4/15], Step [130/469], Reconst Loss: 11777.2119, KL Div: 3094.8594\n",
      "Epoch[4/15], Step [140/469], Reconst Loss: 11389.3096, KL Div: 2999.8645\n",
      "Epoch[4/15], Step [150/469], Reconst Loss: 11418.6328, KL Div: 3236.4045\n",
      "Epoch[4/15], Step [160/469], Reconst Loss: 11659.7910, KL Div: 3136.6328\n",
      "Epoch[4/15], Step [170/469], Reconst Loss: 11394.0381, KL Div: 3121.6343\n",
      "Epoch[4/15], Step [180/469], Reconst Loss: 11415.7930, KL Div: 3112.3481\n",
      "Epoch[4/15], Step [190/469], Reconst Loss: 11604.8457, KL Div: 3027.1396\n",
      "Epoch[4/15], Step [200/469], Reconst Loss: 11152.2363, KL Div: 3090.3677\n",
      "Epoch[4/15], Step [210/469], Reconst Loss: 11423.0928, KL Div: 3196.5623\n",
      "Epoch[4/15], Step [220/469], Reconst Loss: 11397.3887, KL Div: 3071.6191\n",
      "Epoch[4/15], Step [230/469], Reconst Loss: 11264.4004, KL Div: 3133.1460\n",
      "Epoch[4/15], Step [240/469], Reconst Loss: 11041.9561, KL Div: 3071.5908\n",
      "Epoch[4/15], Step [250/469], Reconst Loss: 10827.3418, KL Div: 3142.2908\n",
      "Epoch[4/15], Step [260/469], Reconst Loss: 11643.3047, KL Div: 3058.7144\n",
      "Epoch[4/15], Step [270/469], Reconst Loss: 11425.9258, KL Div: 3119.7734\n",
      "Epoch[4/15], Step [280/469], Reconst Loss: 11000.4961, KL Div: 3085.7585\n",
      "Epoch[4/15], Step [290/469], Reconst Loss: 10827.0586, KL Div: 3072.6792\n",
      "Epoch[4/15], Step [300/469], Reconst Loss: 11231.4932, KL Div: 3079.5288\n",
      "Epoch[4/15], Step [310/469], Reconst Loss: 11531.6172, KL Div: 3124.2793\n",
      "Epoch[4/15], Step [320/469], Reconst Loss: 11202.6621, KL Div: 3104.8967\n",
      "Epoch[4/15], Step [330/469], Reconst Loss: 11114.3730, KL Div: 3085.0784\n",
      "Epoch[4/15], Step [340/469], Reconst Loss: 11393.3125, KL Div: 3116.8662\n",
      "Epoch[4/15], Step [350/469], Reconst Loss: 10934.9551, KL Div: 3087.9658\n",
      "Epoch[4/15], Step [360/469], Reconst Loss: 11576.5781, KL Div: 3060.5569\n",
      "Epoch[4/15], Step [370/469], Reconst Loss: 10848.1875, KL Div: 3149.0215\n",
      "Epoch[4/15], Step [380/469], Reconst Loss: 11424.2832, KL Div: 3200.9607\n",
      "Epoch[4/15], Step [390/469], Reconst Loss: 11425.8076, KL Div: 3147.5645\n",
      "Epoch[4/15], Step [400/469], Reconst Loss: 11071.5547, KL Div: 3129.6345\n",
      "Epoch[4/15], Step [410/469], Reconst Loss: 11104.8203, KL Div: 3084.6096\n",
      "Epoch[4/15], Step [420/469], Reconst Loss: 10699.9150, KL Div: 3002.8130\n",
      "Epoch[4/15], Step [430/469], Reconst Loss: 11353.7441, KL Div: 3212.9878\n",
      "Epoch[4/15], Step [440/469], Reconst Loss: 10975.6426, KL Div: 3229.2244\n",
      "Epoch[4/15], Step [450/469], Reconst Loss: 10941.1973, KL Div: 3124.2695\n",
      "Epoch[4/15], Step [460/469], Reconst Loss: 10927.9424, KL Div: 3062.0293\n",
      "Epoch[5/15], Step [10/469], Reconst Loss: 10799.3301, KL Div: 3139.1282\n",
      "Epoch[5/15], Step [20/469], Reconst Loss: 11321.6592, KL Div: 3167.1919\n",
      "Epoch[5/15], Step [30/469], Reconst Loss: 11147.3398, KL Div: 3121.5176\n",
      "Epoch[5/15], Step [40/469], Reconst Loss: 10887.6816, KL Div: 3234.4717\n",
      "Epoch[5/15], Step [50/469], Reconst Loss: 10913.4102, KL Div: 3044.5564\n",
      "Epoch[5/15], Step [60/469], Reconst Loss: 11184.7891, KL Div: 3143.5771\n",
      "Epoch[5/15], Step [70/469], Reconst Loss: 11506.8242, KL Div: 3205.6875\n",
      "Epoch[5/15], Step [80/469], Reconst Loss: 11232.4023, KL Div: 3126.6294\n",
      "Epoch[5/15], Step [90/469], Reconst Loss: 10476.7207, KL Div: 3070.5566\n",
      "Epoch[5/15], Step [100/469], Reconst Loss: 10339.7842, KL Div: 3077.0132\n",
      "Epoch[5/15], Step [110/469], Reconst Loss: 11149.8125, KL Div: 3119.0962\n",
      "Epoch[5/15], Step [120/469], Reconst Loss: 10698.6934, KL Div: 3101.9236\n",
      "Epoch[5/15], Step [130/469], Reconst Loss: 11091.9834, KL Div: 3172.0146\n",
      "Epoch[5/15], Step [140/469], Reconst Loss: 10788.5527, KL Div: 3088.9668\n",
      "Epoch[5/15], Step [150/469], Reconst Loss: 11304.3633, KL Div: 3069.7996\n",
      "Epoch[5/15], Step [160/469], Reconst Loss: 10965.4717, KL Div: 3243.0549\n",
      "Epoch[5/15], Step [170/469], Reconst Loss: 10935.7285, KL Div: 2995.9224\n",
      "Epoch[5/15], Step [180/469], Reconst Loss: 10470.6289, KL Div: 3183.4829\n",
      "Epoch[5/15], Step [190/469], Reconst Loss: 10933.9717, KL Div: 3123.7871\n",
      "Epoch[5/15], Step [200/469], Reconst Loss: 10639.3730, KL Div: 3011.6187\n",
      "Epoch[5/15], Step [210/469], Reconst Loss: 11205.7988, KL Div: 3099.4521\n",
      "Epoch[5/15], Step [220/469], Reconst Loss: 10590.6738, KL Div: 3189.2949\n",
      "Epoch[5/15], Step [230/469], Reconst Loss: 11350.9219, KL Div: 3210.4431\n",
      "Epoch[5/15], Step [240/469], Reconst Loss: 10872.6787, KL Div: 3116.6267\n",
      "Epoch[5/15], Step [250/469], Reconst Loss: 10430.0361, KL Div: 3027.8215\n",
      "Epoch[5/15], Step [260/469], Reconst Loss: 10397.4258, KL Div: 3170.0098\n",
      "Epoch[5/15], Step [270/469], Reconst Loss: 11150.1895, KL Div: 3123.0469\n",
      "Epoch[5/15], Step [280/469], Reconst Loss: 11051.6709, KL Div: 3136.0137\n",
      "Epoch[5/15], Step [290/469], Reconst Loss: 11038.0039, KL Div: 3213.4087\n",
      "Epoch[5/15], Step [300/469], Reconst Loss: 11537.5605, KL Div: 3182.2556\n",
      "Epoch[5/15], Step [310/469], Reconst Loss: 10379.2930, KL Div: 3036.5557\n",
      "Epoch[5/15], Step [320/469], Reconst Loss: 10952.4512, KL Div: 3144.7720\n",
      "Epoch[5/15], Step [330/469], Reconst Loss: 11020.6416, KL Div: 3209.6389\n",
      "Epoch[5/15], Step [340/469], Reconst Loss: 10561.5811, KL Div: 3120.2134\n",
      "Epoch[5/15], Step [350/469], Reconst Loss: 10875.9053, KL Div: 3168.5762\n",
      "Epoch[5/15], Step [360/469], Reconst Loss: 10884.5000, KL Div: 3149.8643\n",
      "Epoch[5/15], Step [370/469], Reconst Loss: 10569.9316, KL Div: 3189.9517\n",
      "Epoch[5/15], Step [380/469], Reconst Loss: 10725.5938, KL Div: 3147.6021\n",
      "Epoch[5/15], Step [390/469], Reconst Loss: 10987.5645, KL Div: 3155.0767\n",
      "Epoch[5/15], Step [400/469], Reconst Loss: 10726.0869, KL Div: 3124.7507\n",
      "Epoch[5/15], Step [410/469], Reconst Loss: 11384.8564, KL Div: 3167.8152\n",
      "Epoch[5/15], Step [420/469], Reconst Loss: 11167.6855, KL Div: 3073.5635\n",
      "Epoch[5/15], Step [430/469], Reconst Loss: 10721.3242, KL Div: 3108.4390\n",
      "Epoch[5/15], Step [440/469], Reconst Loss: 11164.9512, KL Div: 3149.8987\n",
      "Epoch[5/15], Step [450/469], Reconst Loss: 10527.2969, KL Div: 3170.7534\n",
      "Epoch[5/15], Step [460/469], Reconst Loss: 11082.3916, KL Div: 3107.1416\n",
      "Epoch[6/15], Step [10/469], Reconst Loss: 10764.1416, KL Div: 3211.2954\n",
      "Epoch[6/15], Step [20/469], Reconst Loss: 11102.3096, KL Div: 3108.7773\n",
      "Epoch[6/15], Step [30/469], Reconst Loss: 10745.0117, KL Div: 3275.2466\n",
      "Epoch[6/15], Step [40/469], Reconst Loss: 11352.5166, KL Div: 3175.3296\n",
      "Epoch[6/15], Step [50/469], Reconst Loss: 10946.1250, KL Div: 3156.0369\n",
      "Epoch[6/15], Step [60/469], Reconst Loss: 10584.9961, KL Div: 3247.6018\n",
      "Epoch[6/15], Step [70/469], Reconst Loss: 10310.9453, KL Div: 3122.7070\n",
      "Epoch[6/15], Step [80/469], Reconst Loss: 10694.4980, KL Div: 3204.5220\n",
      "Epoch[6/15], Step [90/469], Reconst Loss: 10741.2676, KL Div: 3270.1028\n",
      "Epoch[6/15], Step [100/469], Reconst Loss: 11136.4121, KL Div: 3102.2070\n",
      "Epoch[6/15], Step [110/469], Reconst Loss: 10666.2754, KL Div: 3187.8020\n",
      "Epoch[6/15], Step [120/469], Reconst Loss: 10707.5762, KL Div: 3094.9668\n",
      "Epoch[6/15], Step [130/469], Reconst Loss: 10720.8301, KL Div: 3110.0176\n",
      "Epoch[6/15], Step [140/469], Reconst Loss: 10345.7031, KL Div: 3139.2886\n",
      "Epoch[6/15], Step [150/469], Reconst Loss: 10950.3018, KL Div: 3147.4961\n",
      "Epoch[6/15], Step [160/469], Reconst Loss: 10663.3975, KL Div: 3174.5298\n",
      "Epoch[6/15], Step [170/469], Reconst Loss: 10636.8223, KL Div: 3104.6738\n",
      "Epoch[6/15], Step [180/469], Reconst Loss: 10504.5312, KL Div: 3131.6204\n",
      "Epoch[6/15], Step [190/469], Reconst Loss: 11131.0449, KL Div: 3248.7046\n",
      "Epoch[6/15], Step [200/469], Reconst Loss: 10613.4268, KL Div: 3243.0215\n",
      "Epoch[6/15], Step [210/469], Reconst Loss: 10886.9883, KL Div: 3294.9434\n",
      "Epoch[6/15], Step [220/469], Reconst Loss: 10422.4746, KL Div: 3122.6272\n",
      "Epoch[6/15], Step [230/469], Reconst Loss: 10688.8242, KL Div: 3096.7761\n",
      "Epoch[6/15], Step [240/469], Reconst Loss: 10614.5273, KL Div: 3136.3833\n",
      "Epoch[6/15], Step [250/469], Reconst Loss: 10886.7441, KL Div: 3056.6206\n",
      "Epoch[6/15], Step [260/469], Reconst Loss: 10839.4795, KL Div: 3340.0071\n",
      "Epoch[6/15], Step [270/469], Reconst Loss: 10915.4062, KL Div: 3186.9775\n",
      "Epoch[6/15], Step [280/469], Reconst Loss: 10943.6074, KL Div: 3206.3479\n",
      "Epoch[6/15], Step [290/469], Reconst Loss: 11258.3848, KL Div: 3227.3062\n",
      "Epoch[6/15], Step [300/469], Reconst Loss: 10556.2324, KL Div: 3142.4688\n",
      "Epoch[6/15], Step [310/469], Reconst Loss: 10371.7109, KL Div: 3154.0117\n",
      "Epoch[6/15], Step [320/469], Reconst Loss: 10802.1973, KL Div: 3191.3967\n",
      "Epoch[6/15], Step [330/469], Reconst Loss: 10968.6064, KL Div: 3102.3420\n",
      "Epoch[6/15], Step [340/469], Reconst Loss: 10694.3262, KL Div: 3119.9070\n",
      "Epoch[6/15], Step [350/469], Reconst Loss: 10842.2285, KL Div: 3153.1157\n",
      "Epoch[6/15], Step [360/469], Reconst Loss: 10404.9824, KL Div: 3060.4473\n",
      "Epoch[6/15], Step [370/469], Reconst Loss: 10556.0498, KL Div: 3088.2849\n",
      "Epoch[6/15], Step [380/469], Reconst Loss: 10267.1113, KL Div: 3185.7549\n",
      "Epoch[6/15], Step [390/469], Reconst Loss: 10678.8438, KL Div: 3193.9062\n",
      "Epoch[6/15], Step [400/469], Reconst Loss: 10645.7793, KL Div: 3213.6162\n",
      "Epoch[6/15], Step [410/469], Reconst Loss: 10506.4199, KL Div: 3075.1768\n",
      "Epoch[6/15], Step [420/469], Reconst Loss: 10379.1660, KL Div: 3171.8081\n",
      "Epoch[6/15], Step [430/469], Reconst Loss: 10796.6602, KL Div: 3155.6001\n",
      "Epoch[6/15], Step [440/469], Reconst Loss: 10656.8623, KL Div: 3241.8008\n",
      "Epoch[6/15], Step [450/469], Reconst Loss: 10948.1777, KL Div: 3098.0908\n",
      "Epoch[6/15], Step [460/469], Reconst Loss: 10722.0273, KL Div: 3351.9109\n",
      "Epoch[7/15], Step [10/469], Reconst Loss: 10987.4561, KL Div: 3193.0923\n",
      "Epoch[7/15], Step [20/469], Reconst Loss: 10718.4365, KL Div: 3178.1113\n",
      "Epoch[7/15], Step [30/469], Reconst Loss: 10449.3086, KL Div: 3243.2412\n",
      "Epoch[7/15], Step [40/469], Reconst Loss: 10889.2051, KL Div: 3204.9062\n",
      "Epoch[7/15], Step [50/469], Reconst Loss: 10253.8193, KL Div: 3186.1646\n",
      "Epoch[7/15], Step [60/469], Reconst Loss: 10192.8281, KL Div: 3139.4680\n",
      "Epoch[7/15], Step [70/469], Reconst Loss: 10590.6250, KL Div: 3133.0886\n",
      "Epoch[7/15], Step [80/469], Reconst Loss: 10639.6797, KL Div: 3210.8359\n",
      "Epoch[7/15], Step [90/469], Reconst Loss: 11173.7490, KL Div: 3162.6514\n",
      "Epoch[7/15], Step [100/469], Reconst Loss: 10798.8652, KL Div: 3225.6235\n",
      "Epoch[7/15], Step [110/469], Reconst Loss: 10587.3145, KL Div: 3112.4827\n",
      "Epoch[7/15], Step [120/469], Reconst Loss: 10266.3750, KL Div: 3185.3254\n",
      "Epoch[7/15], Step [130/469], Reconst Loss: 10669.5615, KL Div: 3113.8242\n",
      "Epoch[7/15], Step [140/469], Reconst Loss: 10420.7480, KL Div: 3318.8533\n",
      "Epoch[7/15], Step [150/469], Reconst Loss: 10769.7373, KL Div: 3160.2766\n",
      "Epoch[7/15], Step [160/469], Reconst Loss: 11276.5049, KL Div: 3200.4561\n",
      "Epoch[7/15], Step [170/469], Reconst Loss: 10499.5117, KL Div: 3220.2397\n",
      "Epoch[7/15], Step [180/469], Reconst Loss: 10448.9551, KL Div: 3165.0969\n",
      "Epoch[7/15], Step [190/469], Reconst Loss: 10323.0449, KL Div: 3104.0830\n",
      "Epoch[7/15], Step [200/469], Reconst Loss: 10779.3350, KL Div: 3268.3418\n",
      "Epoch[7/15], Step [210/469], Reconst Loss: 10535.6260, KL Div: 3237.0459\n",
      "Epoch[7/15], Step [220/469], Reconst Loss: 10302.5488, KL Div: 3134.6636\n",
      "Epoch[7/15], Step [230/469], Reconst Loss: 10646.1270, KL Div: 3316.9104\n",
      "Epoch[7/15], Step [240/469], Reconst Loss: 10401.6074, KL Div: 3076.5791\n",
      "Epoch[7/15], Step [250/469], Reconst Loss: 10737.4902, KL Div: 3217.9719\n",
      "Epoch[7/15], Step [260/469], Reconst Loss: 10975.1172, KL Div: 3336.7476\n",
      "Epoch[7/15], Step [270/469], Reconst Loss: 10571.3105, KL Div: 3074.6694\n",
      "Epoch[7/15], Step [280/469], Reconst Loss: 10951.5801, KL Div: 3313.9604\n",
      "Epoch[7/15], Step [290/469], Reconst Loss: 9936.5205, KL Div: 3120.4285\n",
      "Epoch[7/15], Step [300/469], Reconst Loss: 10047.4453, KL Div: 3137.4824\n",
      "Epoch[7/15], Step [310/469], Reconst Loss: 10456.7168, KL Div: 3210.3018\n",
      "Epoch[7/15], Step [320/469], Reconst Loss: 10279.6074, KL Div: 3209.2686\n",
      "Epoch[7/15], Step [330/469], Reconst Loss: 10464.9551, KL Div: 3277.9851\n",
      "Epoch[7/15], Step [340/469], Reconst Loss: 10237.5332, KL Div: 3137.9136\n",
      "Epoch[7/15], Step [350/469], Reconst Loss: 10627.9141, KL Div: 3184.0664\n",
      "Epoch[7/15], Step [360/469], Reconst Loss: 10584.1855, KL Div: 3189.3455\n",
      "Epoch[7/15], Step [370/469], Reconst Loss: 10613.4697, KL Div: 3206.1460\n",
      "Epoch[7/15], Step [380/469], Reconst Loss: 10236.9248, KL Div: 3229.1846\n",
      "Epoch[7/15], Step [390/469], Reconst Loss: 10406.4639, KL Div: 3133.5161\n",
      "Epoch[7/15], Step [400/469], Reconst Loss: 10404.6387, KL Div: 3235.1653\n",
      "Epoch[7/15], Step [410/469], Reconst Loss: 10750.4365, KL Div: 3187.4805\n",
      "Epoch[7/15], Step [420/469], Reconst Loss: 11351.4053, KL Div: 3227.7104\n",
      "Epoch[7/15], Step [430/469], Reconst Loss: 10628.8682, KL Div: 3220.5793\n",
      "Epoch[7/15], Step [440/469], Reconst Loss: 10776.7090, KL Div: 3302.9229\n",
      "Epoch[7/15], Step [450/469], Reconst Loss: 10752.3232, KL Div: 3190.5586\n",
      "Epoch[7/15], Step [460/469], Reconst Loss: 10259.1035, KL Div: 3173.8679\n",
      "Epoch[8/15], Step [10/469], Reconst Loss: 10427.3457, KL Div: 3245.9810\n",
      "Epoch[8/15], Step [20/469], Reconst Loss: 10612.6309, KL Div: 3218.6038\n",
      "Epoch[8/15], Step [30/469], Reconst Loss: 10469.2891, KL Div: 3249.4744\n",
      "Epoch[8/15], Step [40/469], Reconst Loss: 10446.1387, KL Div: 3291.9155\n",
      "Epoch[8/15], Step [50/469], Reconst Loss: 10524.1396, KL Div: 3327.1106\n",
      "Epoch[8/15], Step [60/469], Reconst Loss: 10348.0830, KL Div: 3172.1108\n",
      "Epoch[8/15], Step [70/469], Reconst Loss: 10252.9336, KL Div: 3212.7612\n",
      "Epoch[8/15], Step [80/469], Reconst Loss: 10428.5781, KL Div: 3132.4819\n",
      "Epoch[8/15], Step [90/469], Reconst Loss: 11022.8867, KL Div: 3263.9165\n",
      "Epoch[8/15], Step [100/469], Reconst Loss: 11015.3262, KL Div: 3248.0195\n",
      "Epoch[8/15], Step [110/469], Reconst Loss: 10251.9854, KL Div: 3237.5786\n",
      "Epoch[8/15], Step [120/469], Reconst Loss: 10391.0459, KL Div: 3220.2727\n",
      "Epoch[8/15], Step [130/469], Reconst Loss: 10736.7188, KL Div: 3272.8335\n",
      "Epoch[8/15], Step [140/469], Reconst Loss: 10750.5391, KL Div: 3207.0208\n",
      "Epoch[8/15], Step [150/469], Reconst Loss: 10640.5508, KL Div: 3290.5889\n",
      "Epoch[8/15], Step [160/469], Reconst Loss: 10206.2910, KL Div: 3213.4951\n",
      "Epoch[8/15], Step [170/469], Reconst Loss: 10336.3594, KL Div: 3165.3706\n",
      "Epoch[8/15], Step [180/469], Reconst Loss: 10447.5557, KL Div: 3216.4092\n",
      "Epoch[8/15], Step [190/469], Reconst Loss: 10508.1758, KL Div: 3306.6777\n",
      "Epoch[8/15], Step [200/469], Reconst Loss: 10291.5215, KL Div: 3162.4658\n",
      "Epoch[8/15], Step [210/469], Reconst Loss: 10437.6592, KL Div: 3195.2417\n",
      "Epoch[8/15], Step [220/469], Reconst Loss: 10763.7754, KL Div: 3167.2964\n",
      "Epoch[8/15], Step [230/469], Reconst Loss: 10508.5605, KL Div: 3270.6831\n",
      "Epoch[8/15], Step [240/469], Reconst Loss: 10686.8008, KL Div: 3257.9585\n",
      "Epoch[8/15], Step [250/469], Reconst Loss: 10299.5303, KL Div: 3121.2754\n",
      "Epoch[8/15], Step [260/469], Reconst Loss: 10250.2363, KL Div: 3162.8008\n",
      "Epoch[8/15], Step [270/469], Reconst Loss: 10540.7920, KL Div: 3300.1074\n",
      "Epoch[8/15], Step [280/469], Reconst Loss: 10794.7051, KL Div: 3318.1499\n",
      "Epoch[8/15], Step [290/469], Reconst Loss: 9947.0449, KL Div: 3197.5508\n",
      "Epoch[8/15], Step [300/469], Reconst Loss: 10984.4531, KL Div: 3338.6121\n",
      "Epoch[8/15], Step [310/469], Reconst Loss: 10905.5947, KL Div: 3317.5701\n",
      "Epoch[8/15], Step [320/469], Reconst Loss: 10784.0234, KL Div: 3330.4749\n",
      "Epoch[8/15], Step [330/469], Reconst Loss: 10139.5488, KL Div: 3241.5625\n",
      "Epoch[8/15], Step [340/469], Reconst Loss: 10390.6738, KL Div: 3193.1348\n",
      "Epoch[8/15], Step [350/469], Reconst Loss: 10502.7500, KL Div: 3346.6021\n",
      "Epoch[8/15], Step [360/469], Reconst Loss: 10547.9307, KL Div: 3166.4844\n",
      "Epoch[8/15], Step [370/469], Reconst Loss: 10482.4766, KL Div: 3195.3970\n",
      "Epoch[8/15], Step [380/469], Reconst Loss: 10385.0781, KL Div: 3187.8557\n",
      "Epoch[8/15], Step [390/469], Reconst Loss: 10752.5967, KL Div: 3231.9561\n",
      "Epoch[8/15], Step [400/469], Reconst Loss: 10571.3535, KL Div: 3151.3496\n",
      "Epoch[8/15], Step [410/469], Reconst Loss: 10533.0664, KL Div: 3345.9905\n",
      "Epoch[8/15], Step [420/469], Reconst Loss: 10784.7578, KL Div: 3270.9617\n",
      "Epoch[8/15], Step [430/469], Reconst Loss: 10434.4863, KL Div: 3109.3857\n",
      "Epoch[8/15], Step [440/469], Reconst Loss: 10399.5996, KL Div: 3377.4180\n",
      "Epoch[8/15], Step [450/469], Reconst Loss: 10139.4141, KL Div: 3164.4702\n",
      "Epoch[8/15], Step [460/469], Reconst Loss: 10481.5273, KL Div: 3149.3025\n",
      "Epoch[9/15], Step [10/469], Reconst Loss: 10250.8955, KL Div: 3205.8030\n",
      "Epoch[9/15], Step [20/469], Reconst Loss: 10553.0635, KL Div: 3261.1030\n",
      "Epoch[9/15], Step [30/469], Reconst Loss: 10552.3340, KL Div: 3189.8711\n",
      "Epoch[9/15], Step [40/469], Reconst Loss: 10257.1465, KL Div: 3188.8564\n",
      "Epoch[9/15], Step [50/469], Reconst Loss: 10609.9541, KL Div: 3076.4709\n",
      "Epoch[9/15], Step [60/469], Reconst Loss: 10405.0879, KL Div: 3257.8276\n",
      "Epoch[9/15], Step [70/469], Reconst Loss: 10774.4102, KL Div: 3178.5288\n",
      "Epoch[9/15], Step [80/469], Reconst Loss: 10509.9277, KL Div: 3273.4521\n",
      "Epoch[9/15], Step [90/469], Reconst Loss: 11042.5762, KL Div: 3212.9319\n",
      "Epoch[9/15], Step [100/469], Reconst Loss: 10345.6465, KL Div: 3235.0037\n",
      "Epoch[9/15], Step [110/469], Reconst Loss: 10289.2031, KL Div: 3142.4341\n",
      "Epoch[9/15], Step [120/469], Reconst Loss: 10695.2734, KL Div: 3209.1575\n",
      "Epoch[9/15], Step [130/469], Reconst Loss: 10526.0137, KL Div: 3240.8149\n",
      "Epoch[9/15], Step [140/469], Reconst Loss: 10161.5059, KL Div: 3172.2515\n",
      "Epoch[9/15], Step [150/469], Reconst Loss: 10333.8633, KL Div: 3169.0728\n",
      "Epoch[9/15], Step [160/469], Reconst Loss: 10406.5137, KL Div: 3260.7305\n",
      "Epoch[9/15], Step [170/469], Reconst Loss: 10397.5254, KL Div: 3208.6748\n",
      "Epoch[9/15], Step [180/469], Reconst Loss: 10716.6758, KL Div: 3239.3511\n",
      "Epoch[9/15], Step [190/469], Reconst Loss: 10107.4531, KL Div: 3211.8699\n",
      "Epoch[9/15], Step [200/469], Reconst Loss: 10708.8428, KL Div: 3273.7109\n",
      "Epoch[9/15], Step [210/469], Reconst Loss: 10416.4912, KL Div: 3155.4221\n",
      "Epoch[9/15], Step [220/469], Reconst Loss: 10360.3486, KL Div: 3145.9751\n",
      "Epoch[9/15], Step [230/469], Reconst Loss: 10594.0488, KL Div: 3169.8315\n",
      "Epoch[9/15], Step [240/469], Reconst Loss: 10733.8418, KL Div: 3204.1875\n",
      "Epoch[9/15], Step [250/469], Reconst Loss: 10332.2061, KL Div: 3223.7603\n",
      "Epoch[9/15], Step [260/469], Reconst Loss: 10324.4775, KL Div: 3199.6389\n",
      "Epoch[9/15], Step [270/469], Reconst Loss: 10632.3008, KL Div: 3255.5344\n",
      "Epoch[9/15], Step [280/469], Reconst Loss: 10469.2734, KL Div: 3234.8433\n",
      "Epoch[9/15], Step [290/469], Reconst Loss: 10241.7285, KL Div: 3253.7671\n",
      "Epoch[9/15], Step [300/469], Reconst Loss: 10180.5293, KL Div: 3251.1641\n",
      "Epoch[9/15], Step [310/469], Reconst Loss: 10716.4502, KL Div: 3227.5186\n",
      "Epoch[9/15], Step [320/469], Reconst Loss: 10466.3691, KL Div: 3271.1489\n",
      "Epoch[9/15], Step [330/469], Reconst Loss: 10828.3867, KL Div: 3216.0420\n",
      "Epoch[9/15], Step [340/469], Reconst Loss: 10560.9863, KL Div: 3244.8433\n",
      "Epoch[9/15], Step [350/469], Reconst Loss: 10377.7959, KL Div: 3222.9534\n",
      "Epoch[9/15], Step [360/469], Reconst Loss: 10294.4727, KL Div: 3217.1685\n",
      "Epoch[9/15], Step [370/469], Reconst Loss: 10272.2754, KL Div: 3150.5239\n",
      "Epoch[9/15], Step [380/469], Reconst Loss: 10962.7246, KL Div: 3317.5791\n",
      "Epoch[9/15], Step [390/469], Reconst Loss: 10411.2969, KL Div: 3175.3618\n",
      "Epoch[9/15], Step [400/469], Reconst Loss: 10327.0977, KL Div: 3219.6396\n",
      "Epoch[9/15], Step [410/469], Reconst Loss: 10328.9746, KL Div: 3233.7661\n",
      "Epoch[9/15], Step [420/469], Reconst Loss: 10680.5088, KL Div: 3254.9558\n",
      "Epoch[9/15], Step [430/469], Reconst Loss: 10415.6230, KL Div: 3124.9390\n",
      "Epoch[9/15], Step [440/469], Reconst Loss: 9987.2344, KL Div: 3189.7905\n",
      "Epoch[9/15], Step [450/469], Reconst Loss: 10470.2021, KL Div: 3287.0234\n",
      "Epoch[9/15], Step [460/469], Reconst Loss: 10702.5234, KL Div: 3201.8140\n",
      "Epoch[10/15], Step [10/469], Reconst Loss: 10403.8848, KL Div: 3171.2754\n",
      "Epoch[10/15], Step [20/469], Reconst Loss: 10635.4775, KL Div: 3254.2466\n",
      "Epoch[10/15], Step [30/469], Reconst Loss: 10579.1680, KL Div: 3273.9231\n",
      "Epoch[10/15], Step [40/469], Reconst Loss: 10284.5029, KL Div: 3185.7783\n",
      "Epoch[10/15], Step [50/469], Reconst Loss: 10173.6279, KL Div: 3267.1582\n",
      "Epoch[10/15], Step [60/469], Reconst Loss: 10403.4883, KL Div: 3069.7490\n",
      "Epoch[10/15], Step [70/469], Reconst Loss: 9888.4355, KL Div: 3146.7312\n",
      "Epoch[10/15], Step [80/469], Reconst Loss: 9737.4834, KL Div: 3219.7368\n",
      "Epoch[10/15], Step [90/469], Reconst Loss: 10582.0703, KL Div: 3254.2783\n",
      "Epoch[10/15], Step [100/469], Reconst Loss: 10110.1973, KL Div: 3246.7749\n",
      "Epoch[10/15], Step [110/469], Reconst Loss: 10528.6689, KL Div: 3289.4243\n",
      "Epoch[10/15], Step [120/469], Reconst Loss: 10813.1855, KL Div: 3203.9766\n",
      "Epoch[10/15], Step [130/469], Reconst Loss: 10565.1416, KL Div: 3244.2998\n",
      "Epoch[10/15], Step [140/469], Reconst Loss: 10681.0645, KL Div: 3196.2441\n",
      "Epoch[10/15], Step [150/469], Reconst Loss: 9970.4863, KL Div: 3236.8735\n",
      "Epoch[10/15], Step [160/469], Reconst Loss: 10277.4727, KL Div: 3127.3650\n",
      "Epoch[10/15], Step [170/469], Reconst Loss: 10277.3477, KL Div: 3184.3364\n",
      "Epoch[10/15], Step [180/469], Reconst Loss: 10271.9990, KL Div: 3174.1589\n",
      "Epoch[10/15], Step [190/469], Reconst Loss: 10770.8369, KL Div: 3289.0884\n",
      "Epoch[10/15], Step [200/469], Reconst Loss: 10758.0195, KL Div: 3283.4961\n",
      "Epoch[10/15], Step [210/469], Reconst Loss: 10576.6836, KL Div: 3267.4766\n",
      "Epoch[10/15], Step [220/469], Reconst Loss: 10418.7793, KL Div: 3199.5396\n",
      "Epoch[10/15], Step [230/469], Reconst Loss: 10151.3408, KL Div: 3131.6646\n",
      "Epoch[10/15], Step [240/469], Reconst Loss: 10787.1611, KL Div: 3261.6240\n",
      "Epoch[10/15], Step [250/469], Reconst Loss: 10005.1406, KL Div: 3209.0693\n",
      "Epoch[10/15], Step [260/469], Reconst Loss: 10544.7188, KL Div: 3234.2849\n",
      "Epoch[10/15], Step [270/469], Reconst Loss: 10639.0488, KL Div: 3336.5708\n",
      "Epoch[10/15], Step [280/469], Reconst Loss: 10234.0449, KL Div: 3163.2322\n",
      "Epoch[10/15], Step [290/469], Reconst Loss: 10395.5283, KL Div: 3230.0557\n",
      "Epoch[10/15], Step [300/469], Reconst Loss: 10590.6807, KL Div: 3360.9133\n",
      "Epoch[10/15], Step [310/469], Reconst Loss: 10568.6602, KL Div: 3178.4221\n",
      "Epoch[10/15], Step [320/469], Reconst Loss: 10542.7324, KL Div: 3377.3721\n",
      "Epoch[10/15], Step [330/469], Reconst Loss: 10567.7617, KL Div: 3152.6162\n",
      "Epoch[10/15], Step [340/469], Reconst Loss: 10169.9102, KL Div: 3260.4910\n",
      "Epoch[10/15], Step [350/469], Reconst Loss: 10368.0977, KL Div: 3176.9429\n",
      "Epoch[10/15], Step [360/469], Reconst Loss: 10424.5078, KL Div: 3203.1863\n",
      "Epoch[10/15], Step [370/469], Reconst Loss: 9899.8916, KL Div: 3119.4822\n",
      "Epoch[10/15], Step [380/469], Reconst Loss: 10854.8525, KL Div: 3198.4739\n",
      "Epoch[10/15], Step [390/469], Reconst Loss: 11067.4629, KL Div: 3193.9795\n",
      "Epoch[10/15], Step [400/469], Reconst Loss: 10145.0742, KL Div: 3304.0518\n",
      "Epoch[10/15], Step [410/469], Reconst Loss: 10561.0078, KL Div: 3255.2041\n",
      "Epoch[10/15], Step [420/469], Reconst Loss: 10606.3340, KL Div: 3165.4597\n",
      "Epoch[10/15], Step [430/469], Reconst Loss: 10346.1484, KL Div: 3183.3530\n",
      "Epoch[10/15], Step [440/469], Reconst Loss: 10094.0547, KL Div: 3249.6353\n",
      "Epoch[10/15], Step [450/469], Reconst Loss: 10242.0996, KL Div: 3189.0120\n",
      "Epoch[10/15], Step [460/469], Reconst Loss: 10490.8867, KL Div: 3282.8130\n",
      "Epoch[11/15], Step [10/469], Reconst Loss: 10143.4609, KL Div: 3118.0461\n",
      "Epoch[11/15], Step [20/469], Reconst Loss: 10220.8193, KL Div: 3138.7256\n",
      "Epoch[11/15], Step [30/469], Reconst Loss: 10382.0664, KL Div: 3166.5532\n",
      "Epoch[11/15], Step [40/469], Reconst Loss: 10497.2441, KL Div: 3193.3970\n",
      "Epoch[11/15], Step [50/469], Reconst Loss: 10452.1270, KL Div: 3292.1851\n",
      "Epoch[11/15], Step [60/469], Reconst Loss: 10796.9639, KL Div: 3321.3623\n",
      "Epoch[11/15], Step [70/469], Reconst Loss: 10241.7148, KL Div: 3152.0347\n",
      "Epoch[11/15], Step [80/469], Reconst Loss: 10436.7637, KL Div: 3407.0225\n",
      "Epoch[11/15], Step [90/469], Reconst Loss: 10563.4648, KL Div: 3134.3418\n",
      "Epoch[11/15], Step [100/469], Reconst Loss: 10470.0410, KL Div: 3336.9773\n",
      "Epoch[11/15], Step [110/469], Reconst Loss: 10507.8574, KL Div: 3174.4463\n",
      "Epoch[11/15], Step [120/469], Reconst Loss: 10131.0566, KL Div: 3151.5415\n",
      "Epoch[11/15], Step [130/469], Reconst Loss: 10183.2109, KL Div: 3114.2988\n",
      "Epoch[11/15], Step [140/469], Reconst Loss: 9905.2891, KL Div: 3165.5928\n",
      "Epoch[11/15], Step [150/469], Reconst Loss: 10744.7109, KL Div: 3266.5234\n",
      "Epoch[11/15], Step [160/469], Reconst Loss: 10047.8818, KL Div: 3321.3232\n",
      "Epoch[11/15], Step [170/469], Reconst Loss: 10711.5059, KL Div: 3229.1755\n",
      "Epoch[11/15], Step [180/469], Reconst Loss: 10376.0762, KL Div: 3296.7085\n",
      "Epoch[11/15], Step [190/469], Reconst Loss: 10292.8252, KL Div: 3166.2832\n",
      "Epoch[11/15], Step [200/469], Reconst Loss: 10428.6357, KL Div: 3213.3201\n",
      "Epoch[11/15], Step [210/469], Reconst Loss: 10506.1719, KL Div: 3317.5510\n",
      "Epoch[11/15], Step [220/469], Reconst Loss: 10087.5029, KL Div: 3167.1680\n",
      "Epoch[11/15], Step [230/469], Reconst Loss: 10752.9893, KL Div: 3291.1313\n",
      "Epoch[11/15], Step [240/469], Reconst Loss: 10541.9512, KL Div: 3205.5605\n",
      "Epoch[11/15], Step [250/469], Reconst Loss: 10567.5537, KL Div: 3231.9448\n",
      "Epoch[11/15], Step [260/469], Reconst Loss: 9999.3994, KL Div: 3147.3081\n",
      "Epoch[11/15], Step [270/469], Reconst Loss: 10494.9121, KL Div: 3184.9873\n",
      "Epoch[11/15], Step [280/469], Reconst Loss: 10232.9971, KL Div: 3189.5215\n",
      "Epoch[11/15], Step [290/469], Reconst Loss: 10437.2197, KL Div: 3270.9844\n",
      "Epoch[11/15], Step [300/469], Reconst Loss: 9947.0957, KL Div: 3213.7568\n",
      "Epoch[11/15], Step [310/469], Reconst Loss: 9848.3174, KL Div: 3181.0251\n",
      "Epoch[11/15], Step [320/469], Reconst Loss: 10179.6562, KL Div: 3227.6372\n",
      "Epoch[11/15], Step [330/469], Reconst Loss: 9846.7148, KL Div: 3163.7046\n",
      "Epoch[11/15], Step [340/469], Reconst Loss: 10451.6191, KL Div: 3144.6177\n",
      "Epoch[11/15], Step [350/469], Reconst Loss: 10090.3711, KL Div: 3304.6121\n",
      "Epoch[11/15], Step [360/469], Reconst Loss: 10232.0410, KL Div: 3308.3120\n",
      "Epoch[11/15], Step [370/469], Reconst Loss: 10763.2930, KL Div: 3131.9709\n",
      "Epoch[11/15], Step [380/469], Reconst Loss: 10197.4092, KL Div: 3228.7578\n",
      "Epoch[11/15], Step [390/469], Reconst Loss: 10366.6064, KL Div: 3335.0703\n",
      "Epoch[11/15], Step [400/469], Reconst Loss: 10096.9717, KL Div: 3106.0068\n",
      "Epoch[11/15], Step [410/469], Reconst Loss: 10659.8379, KL Div: 3249.0483\n",
      "Epoch[11/15], Step [420/469], Reconst Loss: 10527.7744, KL Div: 3167.9541\n",
      "Epoch[11/15], Step [430/469], Reconst Loss: 10558.7451, KL Div: 3287.3696\n",
      "Epoch[11/15], Step [440/469], Reconst Loss: 10339.0898, KL Div: 3290.4941\n",
      "Epoch[11/15], Step [450/469], Reconst Loss: 10190.6465, KL Div: 3202.7471\n",
      "Epoch[11/15], Step [460/469], Reconst Loss: 10205.3438, KL Div: 3320.2188\n",
      "Epoch[12/15], Step [10/469], Reconst Loss: 10229.5957, KL Div: 3248.3989\n",
      "Epoch[12/15], Step [20/469], Reconst Loss: 10070.0020, KL Div: 3190.4326\n",
      "Epoch[12/15], Step [30/469], Reconst Loss: 10036.6094, KL Div: 3185.5791\n",
      "Epoch[12/15], Step [40/469], Reconst Loss: 9894.0664, KL Div: 3200.8613\n",
      "Epoch[12/15], Step [50/469], Reconst Loss: 10233.4688, KL Div: 3224.8135\n",
      "Epoch[12/15], Step [60/469], Reconst Loss: 10673.7949, KL Div: 3392.7021\n",
      "Epoch[12/15], Step [70/469], Reconst Loss: 10437.9180, KL Div: 3344.3921\n",
      "Epoch[12/15], Step [80/469], Reconst Loss: 10549.8828, KL Div: 3430.0232\n",
      "Epoch[12/15], Step [90/469], Reconst Loss: 10386.5410, KL Div: 3263.4204\n",
      "Epoch[12/15], Step [100/469], Reconst Loss: 10399.3555, KL Div: 3197.2275\n",
      "Epoch[12/15], Step [110/469], Reconst Loss: 10526.5938, KL Div: 3259.5852\n",
      "Epoch[12/15], Step [120/469], Reconst Loss: 10345.4092, KL Div: 3183.2212\n",
      "Epoch[12/15], Step [130/469], Reconst Loss: 9860.4688, KL Div: 3241.5693\n",
      "Epoch[12/15], Step [140/469], Reconst Loss: 10345.3623, KL Div: 3261.9526\n",
      "Epoch[12/15], Step [150/469], Reconst Loss: 10078.4336, KL Div: 3278.1621\n",
      "Epoch[12/15], Step [160/469], Reconst Loss: 10458.5254, KL Div: 3283.6504\n",
      "Epoch[12/15], Step [170/469], Reconst Loss: 10570.0449, KL Div: 3344.3806\n",
      "Epoch[12/15], Step [180/469], Reconst Loss: 10542.5518, KL Div: 3247.3867\n",
      "Epoch[12/15], Step [190/469], Reconst Loss: 10171.5684, KL Div: 3312.4385\n",
      "Epoch[12/15], Step [200/469], Reconst Loss: 10855.0234, KL Div: 3206.9512\n",
      "Epoch[12/15], Step [210/469], Reconst Loss: 10335.4111, KL Div: 3255.5107\n",
      "Epoch[12/15], Step [220/469], Reconst Loss: 10460.5273, KL Div: 3303.3774\n",
      "Epoch[12/15], Step [230/469], Reconst Loss: 10135.8066, KL Div: 3197.6331\n",
      "Epoch[12/15], Step [240/469], Reconst Loss: 9778.2949, KL Div: 3104.3364\n",
      "Epoch[12/15], Step [250/469], Reconst Loss: 10493.6582, KL Div: 3373.2480\n",
      "Epoch[12/15], Step [260/469], Reconst Loss: 10737.6768, KL Div: 3249.5486\n",
      "Epoch[12/15], Step [270/469], Reconst Loss: 10390.6152, KL Div: 3260.2683\n",
      "Epoch[12/15], Step [280/469], Reconst Loss: 10603.1357, KL Div: 3281.1045\n",
      "Epoch[12/15], Step [290/469], Reconst Loss: 10423.2871, KL Div: 3281.3909\n",
      "Epoch[12/15], Step [300/469], Reconst Loss: 10136.2871, KL Div: 3164.8889\n",
      "Epoch[12/15], Step [310/469], Reconst Loss: 10112.4932, KL Div: 3201.0249\n",
      "Epoch[12/15], Step [320/469], Reconst Loss: 10345.0898, KL Div: 3181.0435\n",
      "Epoch[12/15], Step [330/469], Reconst Loss: 10505.7246, KL Div: 3313.1270\n",
      "Epoch[12/15], Step [340/469], Reconst Loss: 10102.4570, KL Div: 3214.5229\n",
      "Epoch[12/15], Step [350/469], Reconst Loss: 10382.3613, KL Div: 3111.1626\n",
      "Epoch[12/15], Step [360/469], Reconst Loss: 10456.7275, KL Div: 3275.7563\n",
      "Epoch[12/15], Step [370/469], Reconst Loss: 10491.0479, KL Div: 3234.7544\n",
      "Epoch[12/15], Step [380/469], Reconst Loss: 10276.2461, KL Div: 3274.3499\n",
      "Epoch[12/15], Step [390/469], Reconst Loss: 10422.9756, KL Div: 3321.5527\n",
      "Epoch[12/15], Step [400/469], Reconst Loss: 10011.2754, KL Div: 3140.4290\n",
      "Epoch[12/15], Step [410/469], Reconst Loss: 10086.8896, KL Div: 3195.9180\n",
      "Epoch[12/15], Step [420/469], Reconst Loss: 9778.9258, KL Div: 3251.1277\n",
      "Epoch[12/15], Step [430/469], Reconst Loss: 10478.9453, KL Div: 3253.4304\n",
      "Epoch[12/15], Step [440/469], Reconst Loss: 10367.5156, KL Div: 3289.0493\n",
      "Epoch[12/15], Step [450/469], Reconst Loss: 10121.5859, KL Div: 3212.9595\n",
      "Epoch[12/15], Step [460/469], Reconst Loss: 10484.3008, KL Div: 3319.8799\n",
      "Epoch[13/15], Step [10/469], Reconst Loss: 10072.7969, KL Div: 3214.0615\n",
      "Epoch[13/15], Step [20/469], Reconst Loss: 10372.7607, KL Div: 3145.8757\n",
      "Epoch[13/15], Step [30/469], Reconst Loss: 10539.6641, KL Div: 3247.8267\n",
      "Epoch[13/15], Step [40/469], Reconst Loss: 10155.8623, KL Div: 3295.7036\n",
      "Epoch[13/15], Step [50/469], Reconst Loss: 10367.0723, KL Div: 3206.2947\n",
      "Epoch[13/15], Step [60/469], Reconst Loss: 10183.5332, KL Div: 3251.4856\n",
      "Epoch[13/15], Step [70/469], Reconst Loss: 10561.5244, KL Div: 3357.2524\n",
      "Epoch[13/15], Step [80/469], Reconst Loss: 10286.1914, KL Div: 3268.3159\n",
      "Epoch[13/15], Step [90/469], Reconst Loss: 10399.7207, KL Div: 3183.2173\n",
      "Epoch[13/15], Step [100/469], Reconst Loss: 10014.7803, KL Div: 3289.2651\n",
      "Epoch[13/15], Step [110/469], Reconst Loss: 10689.0283, KL Div: 3249.8916\n",
      "Epoch[13/15], Step [120/469], Reconst Loss: 10097.1328, KL Div: 3185.6401\n",
      "Epoch[13/15], Step [130/469], Reconst Loss: 10417.1973, KL Div: 3342.8345\n",
      "Epoch[13/15], Step [140/469], Reconst Loss: 10077.3906, KL Div: 3158.3374\n",
      "Epoch[13/15], Step [150/469], Reconst Loss: 9678.3418, KL Div: 3184.9136\n",
      "Epoch[13/15], Step [160/469], Reconst Loss: 10052.0449, KL Div: 3227.5588\n",
      "Epoch[13/15], Step [170/469], Reconst Loss: 10557.2363, KL Div: 3213.5496\n",
      "Epoch[13/15], Step [180/469], Reconst Loss: 10496.2637, KL Div: 3305.7712\n",
      "Epoch[13/15], Step [190/469], Reconst Loss: 10127.6133, KL Div: 3312.7041\n",
      "Epoch[13/15], Step [200/469], Reconst Loss: 10278.7773, KL Div: 3200.9355\n",
      "Epoch[13/15], Step [210/469], Reconst Loss: 9800.4395, KL Div: 3216.0259\n",
      "Epoch[13/15], Step [220/469], Reconst Loss: 10094.4424, KL Div: 3157.1843\n",
      "Epoch[13/15], Step [230/469], Reconst Loss: 10041.6445, KL Div: 3260.6885\n",
      "Epoch[13/15], Step [240/469], Reconst Loss: 9972.1113, KL Div: 3163.2285\n",
      "Epoch[13/15], Step [250/469], Reconst Loss: 10397.7656, KL Div: 3268.5894\n",
      "Epoch[13/15], Step [260/469], Reconst Loss: 10525.3633, KL Div: 3291.9817\n",
      "Epoch[13/15], Step [270/469], Reconst Loss: 10383.3730, KL Div: 3273.3792\n",
      "Epoch[13/15], Step [280/469], Reconst Loss: 10027.7031, KL Div: 3155.6133\n",
      "Epoch[13/15], Step [290/469], Reconst Loss: 10103.6602, KL Div: 3344.8511\n",
      "Epoch[13/15], Step [300/469], Reconst Loss: 10179.5225, KL Div: 3238.3110\n",
      "Epoch[13/15], Step [310/469], Reconst Loss: 10094.0430, KL Div: 3204.5334\n",
      "Epoch[13/15], Step [320/469], Reconst Loss: 10291.5488, KL Div: 3292.5222\n",
      "Epoch[13/15], Step [330/469], Reconst Loss: 10239.7266, KL Div: 3160.5879\n",
      "Epoch[13/15], Step [340/469], Reconst Loss: 10144.7598, KL Div: 3262.4275\n",
      "Epoch[13/15], Step [350/469], Reconst Loss: 10183.6816, KL Div: 3133.0166\n",
      "Epoch[13/15], Step [360/469], Reconst Loss: 10153.9404, KL Div: 3196.1318\n",
      "Epoch[13/15], Step [370/469], Reconst Loss: 10658.2812, KL Div: 3357.3242\n",
      "Epoch[13/15], Step [380/469], Reconst Loss: 10126.4072, KL Div: 3209.7749\n",
      "Epoch[13/15], Step [390/469], Reconst Loss: 10269.7109, KL Div: 3249.1167\n",
      "Epoch[13/15], Step [400/469], Reconst Loss: 10330.1396, KL Div: 3331.3735\n",
      "Epoch[13/15], Step [410/469], Reconst Loss: 10257.7754, KL Div: 3261.5652\n",
      "Epoch[13/15], Step [420/469], Reconst Loss: 9822.9092, KL Div: 3171.7910\n",
      "Epoch[13/15], Step [430/469], Reconst Loss: 10319.2637, KL Div: 3291.4814\n",
      "Epoch[13/15], Step [440/469], Reconst Loss: 10197.2090, KL Div: 3277.5383\n",
      "Epoch[13/15], Step [450/469], Reconst Loss: 10056.8896, KL Div: 3167.2480\n",
      "Epoch[13/15], Step [460/469], Reconst Loss: 10820.1660, KL Div: 3263.4683\n",
      "Epoch[14/15], Step [10/469], Reconst Loss: 9905.3008, KL Div: 3259.7339\n",
      "Epoch[14/15], Step [20/469], Reconst Loss: 10420.3330, KL Div: 3328.8589\n",
      "Epoch[14/15], Step [30/469], Reconst Loss: 10383.1914, KL Div: 3241.6641\n",
      "Epoch[14/15], Step [40/469], Reconst Loss: 10199.1328, KL Div: 3299.0505\n",
      "Epoch[14/15], Step [50/469], Reconst Loss: 9887.0293, KL Div: 3138.1333\n",
      "Epoch[14/15], Step [60/469], Reconst Loss: 10551.8340, KL Div: 3377.8347\n",
      "Epoch[14/15], Step [70/469], Reconst Loss: 10054.4658, KL Div: 3178.3743\n",
      "Epoch[14/15], Step [80/469], Reconst Loss: 10293.7480, KL Div: 3181.7747\n",
      "Epoch[14/15], Step [90/469], Reconst Loss: 10024.4355, KL Div: 3151.1372\n",
      "Epoch[14/15], Step [100/469], Reconst Loss: 9977.8789, KL Div: 3264.3259\n",
      "Epoch[14/15], Step [110/469], Reconst Loss: 10058.6973, KL Div: 3191.4539\n",
      "Epoch[14/15], Step [120/469], Reconst Loss: 10197.9824, KL Div: 3222.2344\n",
      "Epoch[14/15], Step [130/469], Reconst Loss: 9995.0234, KL Div: 3343.4309\n",
      "Epoch[14/15], Step [140/469], Reconst Loss: 10322.8359, KL Div: 3394.3857\n",
      "Epoch[14/15], Step [150/469], Reconst Loss: 10510.7812, KL Div: 3338.1152\n",
      "Epoch[14/15], Step [160/469], Reconst Loss: 10111.1025, KL Div: 3320.9331\n",
      "Epoch[14/15], Step [170/469], Reconst Loss: 10352.2227, KL Div: 3220.4309\n",
      "Epoch[14/15], Step [180/469], Reconst Loss: 9565.0488, KL Div: 3178.7866\n",
      "Epoch[14/15], Step [190/469], Reconst Loss: 10371.5625, KL Div: 3212.1162\n",
      "Epoch[14/15], Step [200/469], Reconst Loss: 10415.7227, KL Div: 3247.8398\n",
      "Epoch[14/15], Step [210/469], Reconst Loss: 9684.1582, KL Div: 3302.8848\n",
      "Epoch[14/15], Step [220/469], Reconst Loss: 10157.1270, KL Div: 3199.7471\n",
      "Epoch[14/15], Step [230/469], Reconst Loss: 9833.2305, KL Div: 3107.9399\n",
      "Epoch[14/15], Step [240/469], Reconst Loss: 10376.3164, KL Div: 3345.4182\n",
      "Epoch[14/15], Step [250/469], Reconst Loss: 10540.8330, KL Div: 3294.2827\n",
      "Epoch[14/15], Step [260/469], Reconst Loss: 10531.3555, KL Div: 3301.0996\n",
      "Epoch[14/15], Step [270/469], Reconst Loss: 10032.9355, KL Div: 3202.2021\n",
      "Epoch[14/15], Step [280/469], Reconst Loss: 10108.4736, KL Div: 3241.8608\n",
      "Epoch[14/15], Step [290/469], Reconst Loss: 10281.4004, KL Div: 3351.8560\n",
      "Epoch[14/15], Step [300/469], Reconst Loss: 10327.3301, KL Div: 3249.5671\n",
      "Epoch[14/15], Step [310/469], Reconst Loss: 10040.3340, KL Div: 3350.9165\n",
      "Epoch[14/15], Step [320/469], Reconst Loss: 10087.1670, KL Div: 3266.1797\n",
      "Epoch[14/15], Step [330/469], Reconst Loss: 10535.7373, KL Div: 3205.6038\n",
      "Epoch[14/15], Step [340/469], Reconst Loss: 9985.9414, KL Div: 3324.9016\n",
      "Epoch[14/15], Step [350/469], Reconst Loss: 9932.0752, KL Div: 3050.8367\n",
      "Epoch[14/15], Step [360/469], Reconst Loss: 10177.6465, KL Div: 3357.7153\n",
      "Epoch[14/15], Step [370/469], Reconst Loss: 10434.9248, KL Div: 3213.3833\n",
      "Epoch[14/15], Step [380/469], Reconst Loss: 10176.4785, KL Div: 3215.7292\n",
      "Epoch[14/15], Step [390/469], Reconst Loss: 9725.6289, KL Div: 3318.3528\n",
      "Epoch[14/15], Step [400/469], Reconst Loss: 10307.3799, KL Div: 3146.0996\n",
      "Epoch[14/15], Step [410/469], Reconst Loss: 10026.1113, KL Div: 3253.6550\n",
      "Epoch[14/15], Step [420/469], Reconst Loss: 10351.5146, KL Div: 3261.7739\n",
      "Epoch[14/15], Step [430/469], Reconst Loss: 10407.0010, KL Div: 3216.3213\n",
      "Epoch[14/15], Step [440/469], Reconst Loss: 10571.8604, KL Div: 3276.5061\n",
      "Epoch[14/15], Step [450/469], Reconst Loss: 10224.9922, KL Div: 3332.6982\n",
      "Epoch[14/15], Step [460/469], Reconst Loss: 10688.7354, KL Div: 3316.0083\n",
      "Epoch[15/15], Step [10/469], Reconst Loss: 10473.0859, KL Div: 3270.9839\n",
      "Epoch[15/15], Step [20/469], Reconst Loss: 9962.1289, KL Div: 3208.6567\n",
      "Epoch[15/15], Step [30/469], Reconst Loss: 10393.4561, KL Div: 3285.1882\n",
      "Epoch[15/15], Step [40/469], Reconst Loss: 10518.0488, KL Div: 3298.5439\n",
      "Epoch[15/15], Step [50/469], Reconst Loss: 9898.4531, KL Div: 3243.9663\n",
      "Epoch[15/15], Step [60/469], Reconst Loss: 9963.3867, KL Div: 3172.0320\n",
      "Epoch[15/15], Step [70/469], Reconst Loss: 10345.8457, KL Div: 3284.0396\n",
      "Epoch[15/15], Step [80/469], Reconst Loss: 10456.7539, KL Div: 3311.0125\n",
      "Epoch[15/15], Step [90/469], Reconst Loss: 10382.9492, KL Div: 3243.4897\n",
      "Epoch[15/15], Step [100/469], Reconst Loss: 9938.9678, KL Div: 3222.1067\n",
      "Epoch[15/15], Step [110/469], Reconst Loss: 10266.5625, KL Div: 3310.3989\n",
      "Epoch[15/15], Step [120/469], Reconst Loss: 10450.6865, KL Div: 3264.0093\n",
      "Epoch[15/15], Step [130/469], Reconst Loss: 9995.8125, KL Div: 3159.4204\n",
      "Epoch[15/15], Step [140/469], Reconst Loss: 10508.1973, KL Div: 3460.2937\n",
      "Epoch[15/15], Step [150/469], Reconst Loss: 10073.0312, KL Div: 3197.5059\n",
      "Epoch[15/15], Step [160/469], Reconst Loss: 10353.5303, KL Div: 3336.9648\n",
      "Epoch[15/15], Step [170/469], Reconst Loss: 10363.1318, KL Div: 3330.5054\n",
      "Epoch[15/15], Step [180/469], Reconst Loss: 10373.1016, KL Div: 3250.0137\n",
      "Epoch[15/15], Step [190/469], Reconst Loss: 9921.7832, KL Div: 3289.1626\n",
      "Epoch[15/15], Step [200/469], Reconst Loss: 10170.9102, KL Div: 3251.1792\n",
      "Epoch[15/15], Step [210/469], Reconst Loss: 9748.0684, KL Div: 3092.8506\n",
      "Epoch[15/15], Step [220/469], Reconst Loss: 9908.3027, KL Div: 3287.7581\n",
      "Epoch[15/15], Step [230/469], Reconst Loss: 10140.3271, KL Div: 3275.5913\n",
      "Epoch[15/15], Step [240/469], Reconst Loss: 9858.0742, KL Div: 3261.5664\n",
      "Epoch[15/15], Step [250/469], Reconst Loss: 9836.4775, KL Div: 3196.8301\n",
      "Epoch[15/15], Step [260/469], Reconst Loss: 10036.1240, KL Div: 3272.3069\n",
      "Epoch[15/15], Step [270/469], Reconst Loss: 10071.7090, KL Div: 3385.6287\n",
      "Epoch[15/15], Step [280/469], Reconst Loss: 10557.0586, KL Div: 3254.3579\n",
      "Epoch[15/15], Step [290/469], Reconst Loss: 9915.1562, KL Div: 3274.1912\n",
      "Epoch[15/15], Step [300/469], Reconst Loss: 10408.7305, KL Div: 3293.6274\n",
      "Epoch[15/15], Step [310/469], Reconst Loss: 10579.3418, KL Div: 3239.1660\n",
      "Epoch[15/15], Step [320/469], Reconst Loss: 10202.1191, KL Div: 3219.2583\n",
      "Epoch[15/15], Step [330/469], Reconst Loss: 9689.6133, KL Div: 3210.3486\n",
      "Epoch[15/15], Step [340/469], Reconst Loss: 10280.3477, KL Div: 3243.2358\n",
      "Epoch[15/15], Step [350/469], Reconst Loss: 10053.0645, KL Div: 3129.1807\n",
      "Epoch[15/15], Step [360/469], Reconst Loss: 10163.8027, KL Div: 3279.6387\n",
      "Epoch[15/15], Step [370/469], Reconst Loss: 9968.8555, KL Div: 3306.9771\n",
      "Epoch[15/15], Step [380/469], Reconst Loss: 10040.5645, KL Div: 3130.4800\n",
      "Epoch[15/15], Step [390/469], Reconst Loss: 9998.8867, KL Div: 3152.7051\n",
      "Epoch[15/15], Step [400/469], Reconst Loss: 10243.8906, KL Div: 3228.1226\n",
      "Epoch[15/15], Step [410/469], Reconst Loss: 9754.8730, KL Div: 3150.7825\n",
      "Epoch[15/15], Step [420/469], Reconst Loss: 9754.5742, KL Div: 3240.9683\n",
      "Epoch[15/15], Step [430/469], Reconst Loss: 9948.7148, KL Div: 3127.5784\n",
      "Epoch[15/15], Step [440/469], Reconst Loss: 10673.8418, KL Div: 3359.7185\n",
      "Epoch[15/15], Step [450/469], Reconst Loss: 10039.2266, KL Div: 3175.0171\n",
      "Epoch[15/15], Step [460/469], Reconst Loss: 10278.3408, KL Div: 3338.0635\n"
     ]
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "\n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        # For KL divergence, see Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
    "        reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\"\n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 1, 28, 28)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-19T08:02:52.980939100Z",
     "start_time": "2023-05-19T08:01:52.744771400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
