{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 如何计算卷积网络的网络参数量\n",
    "\n",
    "以 `AlexNet` 作为示例网络，输入数据为[1,1,28,28]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "211f0e5c092f4030"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:09.537688900Z",
     "start_time": "2023-12-27T01:50:09.533616900Z"
    }
   },
   "id": "e399a26687da3c0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:11.306669100Z",
     "start_time": "2023-12-27T01:50:11.029485200Z"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    # 这里使用一个11*11的更大窗口来捕捉对象。\n",
    "    # 同时，步幅为4，以减少输出的高度和宽度。\n",
    "    # 另外，输出通道的数目远大于LeNet\n",
    "    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    # 使用三个连续的卷积层和较小的卷积窗口。\n",
    "    # 除了最后的卷积层，输出通道的数量进一步增加。\n",
    "    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度\n",
    "    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "    nn.Flatten(),\n",
    "    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合\n",
    "    nn.Linear(6400, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(4096, 4096), nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "    nn.Linear(4096, 10))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 计算卷积层的输出大小\n",
    "def calculate_conv_output_size(input_size, kernel_size, padding, stride):\n",
    "    return (input_size - kernel_size + 2 * padding) // stride + 1\n",
    "\n",
    "\n",
    "# 计算汇聚层的输出大小\n",
    "def calculate_pooling_output_size(input_size, pooling_size, stride):\n",
    "    return (input_size - pooling_size) // stride + 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:13.164744300Z",
     "start_time": "2023-12-27T01:50:13.159372200Z"
    }
   },
   "id": "1e15b61a242414e",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卷积层输出大小：54 [核：11，填充：1 步幅：4]\n",
      "卷积层参数大小：11712\n",
      "汇聚层输出大小：26 [核：3，步幅：2]\n",
      "卷积层输出大小：26 [核：5，填充：2 步幅：1]\n",
      "卷积层参数大小：614656\n",
      "汇聚层输出大小：12 [核：3，步幅：2]\n",
      "卷积层输出大小：12 [核：3，填充：1 步幅：1]\n",
      "卷积层参数大小：885120\n",
      "卷积层输出大小：12 [核：3，填充：1 步幅：1]\n",
      "卷积层参数大小：1327488\n",
      "卷积层输出大小：12 [核：3，填充：1 步幅：1]\n",
      "卷积层参数大小：884992\n",
      "汇聚层输出大小：5 [核：3，步幅：2]\n",
      "全连接层参数大小：26214400\n",
      "全连接层参数大小：16777216\n",
      "全连接层参数大小：40960\n",
      "总参数量：46756544\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1, 1, 224, 224)\n",
    "\n",
    "total_params = 0\n",
    "\n",
    "for layer in net:\n",
    "    if layer.__class__.__name__ == 'MaxPool2d':\n",
    "        pooling_output_size = calculate_pooling_output_size(X.shape[2], layer.kernel_size, layer.stride)\n",
    "        print(f\"汇聚层输出大小：{pooling_output_size} [核：{layer.kernel_size}，步幅：{layer.stride}]\")\n",
    "\n",
    "    # 卷基层\n",
    "    if layer.__class__.__name__ == 'Conv2d':\n",
    "        conv_output_size = calculate_conv_output_size(X.shape[2], layer.kernel_size[0], layer.padding[0],\n",
    "                                                      layer.stride[0])\n",
    "        print(f\"卷积层输出大小：{conv_output_size} [核：{layer.kernel_size[0]}，\"\n",
    "              f\"填充：{layer.padding[0]} 步幅：{layer.stride[0]}]\", )\n",
    "\n",
    "        layer_params = (layer.kernel_size[0] * layer.kernel_size[1] * layer.in_channels + 1) * layer.out_channels\n",
    "        print(f\"卷积层参数大小：{layer_params}\")\n",
    "        total_params += layer_params\n",
    "\n",
    "    # 全连接层\n",
    "    if layer.__class__.__name__ == 'Linear':\n",
    "        layer_params = layer.in_features * layer.out_features\n",
    "        print(f\"全连接层参数大小：{layer_params}\")\n",
    "        total_params += layer_params\n",
    "\n",
    "    X = layer(X)\n",
    "    # print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n",
    "\n",
    "print(f\"总参数量：{total_params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:14.823758200Z",
     "start_time": "2023-12-27T01:50:14.770231200Z"
    }
   },
   "id": "5b16edfe69f81c18",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.pooling.MaxPool2d'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.dropout.Dropout'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "params: 46764746.0\n"
     ]
    }
   ],
   "source": [
    "# 使用第三方库\n",
    "from thop import profile\n",
    "\n",
    "input = torch.randn(1, 1, 224, 224)\n",
    "\n",
    "\n",
    "def count_your_model(model, x, y):\n",
    "    print(\"count\")\n",
    "    # your rule here\n",
    "\n",
    "\n",
    "macs, params = profile(net, inputs=(input,),\n",
    "                       custom_ops={net: count_your_model})\n",
    "print(f'params: {params}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:17.842117800Z",
     "start_time": "2023-12-27T01:50:17.792739200Z"
    }
   },
   "id": "a9103ca09e91edc9",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params: 46764746\n",
      "Estimated memory usage for parameters: 178.39334869384766 MB\n"
     ]
    }
   ],
   "source": [
    "params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(f'params: {params}')\n",
    "\n",
    "# 估算显存占用量（仅考虑参数量）\n",
    "estimated_memory = params * 4  # float32 数据类型每个元素占用4个字节\n",
    "print(f\"Estimated memory usage for parameters: {estimated_memory / 1024 / 1024} MB\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T01:50:49.818763200Z",
     "start_time": "2023-12-27T01:50:49.811055400Z"
    }
   },
   "id": "b73acf9e9cb06160",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "**参数量 = 卷积层的参数量 + 全连接层的参数量**\n",
    "\n",
    "卷积层的参数量 = (卷积核大小 * 卷积核大小 * 输入通道数 + 1) * 输出通道数。\n",
    "    1 为 bias 数量\n",
    "全连接层的参数量 = 输入神经元个数 * 输出神经元个数 + B\n",
    "    B 为 bias 数量\n",
    "\n",
    "以[1,1,224,224]为输入数据\n",
    "第一层卷积参数量：(11 * 11 * 1 + 1) * 96\n",
    "第二层卷积参数量：(5 * 5 * 96 + 1) * 256\n",
    "...\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9f13b73e0e65769"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
