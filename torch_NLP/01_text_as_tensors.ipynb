{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "表示文本的方法：\n",
    "- 字符级别表示\n",
    "- 单词级别表示\n",
    "\n",
    "我们通常将一段原子文本称为令牌（`token`），令牌可以是字符、单词、或部分单词。将文本转换成令牌列表的过程称之为 `tokenization`，接下来，我们需要将每个令牌分配给一个数字，我们可以将其输入神经网络，这称为矢量化（`vectorization`），通常通过构建令牌词汇表来完成。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:16:33.338239600Z",
     "start_time": "2023-06-12T03:16:33.332240100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "os.makedirs('./data', exist_ok=True)\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='./data')\n",
    "\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:20:16.096347100Z",
     "start_time": "2023-06-12T03:20:16.091270700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ping\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
      "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'Lock'\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m5\u001B[39m), train_dataset):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m**\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclasses[x[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m** -> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(train_dataset)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\sharding.py:75\u001B[0m, in \u001B[0;36mShardingFilterIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe):\n\u001B[0;32m     76\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_of_instances \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minstance_id:\n\u001B[0;32m     77\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m item\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combinatorics.py:124\u001B[0m, in \u001B[0;36mShufflerIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[0;32m    123\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_enabled:\n\u001B[1;32m--> 124\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[0;32m    125\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m x\n\u001B[0;32m    126\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:122\u001B[0m, in \u001B[0;36mMapperIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_fn(data)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\plain_text_reader.py:168\u001B[0m, in \u001B[0;36m_CSVBaseParserIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    167\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Union[D, Tuple[\u001B[38;5;28mstr\u001B[39m, D]]]:\n\u001B[1;32m--> 168\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m path, file \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m    169\u001B[0m         stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_helper\u001B[38;5;241m.\u001B[39mskip_lines(file)\n\u001B[0;32m    170\u001B[0m         stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_helper\u001B[38;5;241m.\u001B[39mdecode(stream)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\fileopener.py:67\u001B[0m, in \u001B[0;36mFileOpenerIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m---> 67\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m get_file_binaries_from_pathnames(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoding)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\utils\\common.py:210\u001B[0m, in \u001B[0;36mget_file_binaries_from_pathnames\u001B[1;34m(pathnames, mode, encoding)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    208\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m mode\n\u001B[1;32m--> 210\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m pathname \u001B[38;5;129;01min\u001B[39;00m pathnames:\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pathname, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    212\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected string type for pathname, but got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    213\u001B[0m                         \u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(pathname)))\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:52\u001B[0m, in \u001B[0;36mConcaterIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m dp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipes:\n\u001B[1;32m---> 52\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m dp:\n\u001B[0;32m     53\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:52\u001B[0m, in \u001B[0;36mConcaterIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator:\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m dp \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipes:\n\u001B[1;32m---> 52\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m dp:\n\u001B[0;32m     53\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:454\u001B[0m, in \u001B[0;36m_FulfilledPromisesIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    449\u001B[0m         \u001B[38;5;66;03m# TODO(VitalyFedyunin): If no match found, that means we exceeded length of memory_cell\u001B[39;00m\n\u001B[0;32m    450\u001B[0m         \u001B[38;5;66;03m# and there is aggressive amount 1-to-zero cases, raise error and explain how to fix\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 454\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m    455\u001B[0m         rec_uuid, record \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory_cell_dp\u001B[38;5;241m.\u001B[39mget_last()\n\u001B[0;32m    456\u001B[0m         original_file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfirst_filepath_fn(record)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\saver.py:53\u001B[0m, in \u001B[0;36mSaverIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m---> 53\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m filepath, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m     54\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     55\u001B[0m             filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfn(filepath)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\hashchecker.py:67\u001B[0m, in \u001B[0;36mHashCheckerIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Tuple[\u001B[38;5;28mstr\u001B[39m, StreamWrapper]]:\n\u001B[1;32m---> 67\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m file_name, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhash_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msha256\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m     69\u001B[0m             hash_func \u001B[38;5;241m=\u001B[39m hashlib\u001B[38;5;241m.\u001B[39msha256()\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:122\u001B[0m, in \u001B[0;36mMapperIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_fn(data)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\callable.py:122\u001B[0m, in \u001B[0;36mMapperIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[T_co]:\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdatapipe:\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply_fn(data)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\load\\online.py:84\u001B[0m, in \u001B[0;36mHTTPReaderIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     83\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[Tuple[\u001B[38;5;28mstr\u001B[39m, StreamWrapper]]:\n\u001B[1;32m---> 84\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m url \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     86\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m _get_response_from_http(url, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimeout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquery_params)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:229\u001B[0m, in \u001B[0;36mOnDiskCacheHolderIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_end_caching_flag:\n\u001B[1;32m--> 229\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    231\u001B[0m         \u001B[38;5;66;03m# In case of BC breaking, use RuntimeError for now. Warning is another option\u001B[39;00m\n\u001B[0;32m    232\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease call `end_caching()` before iteration.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:173\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.wrap_generator\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    171\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 173\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mgen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    176\u001B[0m     datapipe\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:374\u001B[0m, in \u001B[0;36m_MemoryCellIterDataPipe.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__iter__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 374\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_datapipe:\n\u001B[0;32m    375\u001B[0m         item_id \u001B[38;5;241m=\u001B[39m uuid\u001B[38;5;241m.\u001B[39muuid4()\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer_pos \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuffer_pos \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mremember_elements\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:144\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.IteratorDecorator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_next()\n\u001B[0;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Decided against using `contextlib.nullcontext` for performance reasons\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_next\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\_hook_iterator.py:132\u001B[0m, in \u001B[0;36mhook_iterator.<locals>.IteratorDecorator._get_next\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;124;03mReturn next with logic related to iterator validity, profiler, and incrementation of samples yielded.\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m _check_iterator_valid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_dp, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterator_id)\n\u001B[1;32m--> 132\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_and_has_next_method:\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource_dp\u001B[38;5;241m.\u001B[39m_number_of_samples_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:427\u001B[0m, in \u001B[0;36m_DemultiplexerIterDataPipe.get_next_element_by_instance\u001B[1;34m(self, instance_id)\u001B[0m\n\u001B[0;32m    425\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    426\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 427\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_next\u001B[49m\u001B[43m(\u001B[49m\u001B[43minstance_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    428\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[0;32m    429\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_child_stop[instance_id] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\datapipes\\iter\\combining.py:397\u001B[0m, in \u001B[0;36m_DemultiplexerIterDataPipe._find_next\u001B[1;34m(self, instance_id)\u001B[0m\n\u001B[0;32m    393\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    394\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_datapipe_iterator has not been set, likely because this private method is called directly \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    395\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwithout invoking get_next_element_by_instance() first.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    396\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_datapipe_iterator)\n\u001B[1;32m--> 397\u001B[0m classification \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclassifier_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m classification \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdrop_none:\n\u001B[0;32m    399\u001B[0m     StreamWrapper\u001B[38;5;241m.\u001B[39mclose_streams(value)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torchdata\\datapipes\\iter\\util\\cacheholder.py:262\u001B[0m, in \u001B[0;36mOnDiskCacheHolderIterDataPipe._cache_check_fn\u001B[1;34m(data, filepath_fn, hash_dict, hash_type, extra_check_fn, cache_uuid)\u001B[0m\n\u001B[0;32m    259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(dirname):\n\u001B[0;32m    260\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(dirname)\n\u001B[1;32m--> 262\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mportalocker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLock\u001B[49m(promise_filepath, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma+\u001B[39m\u001B[38;5;124m\"\u001B[39m, flags\u001B[38;5;241m=\u001B[39mportalocker\u001B[38;5;241m.\u001B[39mLockFlags\u001B[38;5;241m.\u001B[39mEXCLUSIVE) \u001B[38;5;28;01mas\u001B[39;00m promise_fh:\n\u001B[0;32m    263\u001B[0m     promise_fh\u001B[38;5;241m.\u001B[39mseek(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    264\u001B[0m     data \u001B[38;5;241m=\u001B[39m promise_fh\u001B[38;5;241m.\u001B[39mread()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'Lock'\nThis exception is thrown by __iter__ of _MemoryCellIterDataPipe(remember_elements=1000, source_datapipe=_ChildDataPipe)"
     ]
    }
   ],
   "source": [
    "for i, x in zip(range(5), train_dataset):\n",
    "    print(f\"**{classes[x[0]]}** -> {x[1]}\\n\")\n",
    "\n",
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:18:32.473802600Z",
     "start_time": "2023-06-12T03:18:32.258312600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function _basic_english_normalize at 0x000001EAAD60ED40>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "print(tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:13:51.110523400Z",
     "start_time": "2023-06-12T03:13:51.001894Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m first_sentence \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      2\u001B[0m second_sentence \u001B[38;5;241m=\u001B[39m train_dataset[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m      4\u001B[0m f_tokens \u001B[38;5;241m=\u001B[39m tokenizer(first_sentence)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310-ml\\lib\\site-packages\\torch\\utils\\data\\dataset.py:53\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T_co:\n\u001B[1;32m---> 53\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f'\\nfirst token list:\\n{f_tokens}')\n",
    "print(f'\\nsecond token list:\\n{s_tokens}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-12T03:20:04.601617200Z",
     "start_time": "2023-06-12T03:20:04.495618400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
