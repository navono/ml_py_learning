{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[model](https://learn.microsoft.com/en-us/training/modules/intro-machine-learning-pytorch/4-model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:29:53.718133200Z",
     "start_time": "2023-06-08T06:29:53.712987800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:28:26.653103700Z",
     "start_time": "2023-06-08T06:28:26.651266300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our neural network are composed of the following:\n",
    "\n",
    "- The input layer with 28x28 or 784 features/pixels.\n",
    "- The first linear module takes the input 784 features and transforms it to a hidden layer with 512 features\n",
    "- The ReLU activation function will be applied in the transformation\n",
    "- The second linear module take 512 features as input from the first hidden layer and transforms it to the next hidden layer with 512 features\n",
    "- The ReLU activation function will be applied in the transformation\n",
    "- The third linear module take 512 features as input from the second hidden layer and transforms it to the output layer with 10, which is the number of classes\n",
    "- The ReLU activation function will be applied in the transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:31:26.871561Z",
     "start_time": "2023-06-08T06:31:26.860102100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n",
      "First Linear weights: Parameter containing:\n",
      "tensor([[ 0.0064,  0.0033, -0.0008,  ..., -0.0349,  0.0304, -0.0191],\n",
      "        [ 0.0205,  0.0003,  0.0353,  ..., -0.0287, -0.0056,  0.0316],\n",
      "        [-0.0068, -0.0122, -0.0323,  ...,  0.0143,  0.0106, -0.0085],\n",
      "        ...,\n",
      "        [ 0.0293, -0.0348, -0.0090,  ...,  0.0344, -0.0305, -0.0031],\n",
      "        [-0.0328, -0.0079, -0.0110,  ...,  0.0256,  0.0119,  0.0305],\n",
      "        [ 0.0029, -0.0303, -0.0121,  ...,  0.0206, -0.0227,  0.0142]],\n",
      "       device='cuda:0', requires_grad=True) \n",
      "\n",
      "First Linear weights: Parameter containing:\n",
      "tensor([ 3.3697e-02,  3.3230e-02, -1.2195e-02, -1.8797e-02,  2.7887e-02,\n",
      "         2.7492e-02, -6.9289e-03,  1.3743e-02,  2.4680e-02, -2.3443e-02,\n",
      "         1.7713e-03,  4.6313e-03,  1.5671e-02, -2.9244e-02,  1.6328e-02,\n",
      "        -3.5189e-02, -2.7798e-03, -2.1222e-02, -1.6685e-02, -2.1998e-02,\n",
      "         2.5578e-02, -1.9186e-02,  2.7854e-02, -4.6711e-03, -6.5702e-03,\n",
      "        -4.4641e-03,  2.2182e-02, -2.0114e-02,  3.5602e-02, -2.2977e-02,\n",
      "        -1.0176e-02, -3.3695e-02, -8.4087e-03, -1.2876e-02,  2.1555e-02,\n",
      "         2.1185e-02,  2.8365e-03,  2.7623e-03,  1.5968e-02,  2.1221e-02,\n",
      "         2.9405e-03, -1.3289e-02, -1.8823e-02,  3.3271e-02, -2.4299e-02,\n",
      "        -8.0808e-03, -1.0024e-02, -5.9687e-03,  3.8012e-03, -1.0012e-02,\n",
      "        -3.3144e-02, -3.5578e-02, -1.6374e-02,  3.2681e-02,  2.3428e-02,\n",
      "         2.8835e-02,  2.5295e-02,  3.5555e-03, -4.5604e-03,  2.4098e-02,\n",
      "         2.9199e-02, -6.1834e-03,  3.6469e-03, -1.1307e-02, -3.8417e-03,\n",
      "         1.6046e-02,  2.6797e-02, -3.0499e-02, -8.1975e-03, -3.3714e-02,\n",
      "         1.0683e-02, -2.8217e-02,  5.7479e-03,  2.2689e-02,  2.9034e-02,\n",
      "        -2.4948e-02, -1.6694e-02, -6.5262e-03,  1.5395e-02, -1.7853e-02,\n",
      "        -1.0119e-02, -2.7099e-02, -5.0363e-03,  1.1978e-03, -3.0511e-02,\n",
      "        -3.1859e-02, -1.3089e-02, -1.0145e-02, -4.2186e-03,  2.5973e-02,\n",
      "        -1.8271e-02, -1.1643e-02, -9.9042e-03, -3.3935e-02, -6.5392e-03,\n",
      "        -6.8375e-03,  2.5733e-02, -1.9076e-02, -3.5575e-02,  2.8032e-02,\n",
      "         3.4677e-02,  6.2048e-03, -1.4969e-02,  3.0530e-02, -2.1931e-03,\n",
      "        -3.3277e-02,  1.3817e-02,  2.7128e-02, -1.2420e-02,  1.9558e-02,\n",
      "        -2.8622e-02, -1.6066e-02, -1.2586e-02,  2.1012e-02,  3.6206e-03,\n",
      "         3.1691e-02, -1.7652e-02, -7.4743e-03, -1.3186e-02,  3.5395e-02,\n",
      "        -1.1568e-02, -2.4368e-02, -2.5716e-02,  3.4363e-02,  1.2992e-02,\n",
      "         3.3418e-02, -2.3451e-02, -3.0453e-02, -3.4179e-02, -2.2006e-03,\n",
      "        -7.4377e-03,  1.7639e-02,  1.7981e-02,  3.1024e-02,  9.0677e-03,\n",
      "        -1.9937e-02,  3.1179e-02, -2.5655e-03, -2.7791e-02,  2.5567e-02,\n",
      "         1.3795e-02,  1.4636e-02, -2.0793e-02,  4.5492e-03, -2.8603e-02,\n",
      "         2.3446e-02, -2.3260e-02, -2.3161e-02,  8.8998e-03,  3.2631e-02,\n",
      "        -1.2257e-02, -6.3750e-03, -2.0920e-02,  1.3761e-05,  1.2105e-03,\n",
      "        -1.6288e-02, -3.1183e-02, -3.4952e-02, -1.3899e-03,  1.7318e-02,\n",
      "         1.1113e-02, -2.8582e-02,  1.0023e-02, -1.7768e-02, -4.5856e-03,\n",
      "        -3.5650e-02, -5.9687e-05, -1.0210e-02,  7.8710e-03,  3.3285e-02,\n",
      "         4.2375e-03, -2.4324e-02,  4.9671e-04,  1.1073e-04, -2.4932e-02,\n",
      "        -1.9410e-02, -2.8930e-03, -2.0212e-02, -3.1422e-02, -2.6287e-02,\n",
      "        -2.6667e-02, -9.2557e-03, -1.9871e-02,  1.5141e-02, -3.7760e-03,\n",
      "         8.0763e-03, -2.5939e-02,  2.0171e-02, -1.4103e-03, -3.3715e-03,\n",
      "        -1.5437e-02,  1.6622e-04, -1.3654e-02, -1.9524e-02,  2.8837e-02,\n",
      "         1.3641e-02, -2.9779e-02, -2.4524e-02,  2.5522e-02, -2.7658e-02,\n",
      "         2.7997e-02,  2.1474e-02,  2.3542e-02, -2.5325e-02,  2.8755e-03,\n",
      "        -1.6764e-02,  2.4098e-02,  1.8377e-02, -2.8705e-02,  3.3750e-02,\n",
      "        -1.7223e-02,  2.1111e-02,  7.4866e-03,  4.1352e-03,  3.3542e-02,\n",
      "         2.3355e-02, -1.4643e-02, -1.4535e-02, -1.2221e-02, -7.3368e-04,\n",
      "         1.5505e-02, -2.3153e-02, -2.4273e-03,  6.4774e-03, -3.5396e-02,\n",
      "         7.2774e-03, -8.6462e-03, -3.5076e-03,  1.8078e-02, -3.3921e-02,\n",
      "        -2.4991e-02,  1.0135e-02,  2.0085e-02, -2.2271e-02, -7.8309e-03,\n",
      "         6.2125e-03,  5.0690e-03,  2.4319e-02,  8.2349e-03, -3.2759e-03,\n",
      "         3.5171e-02, -1.4196e-02, -4.7231e-03,  2.7145e-02, -2.5780e-02,\n",
      "         5.7640e-03, -1.0059e-02, -2.2578e-02,  3.0078e-02, -2.2863e-02,\n",
      "         2.8512e-02, -2.3641e-02, -3.0004e-02,  3.5093e-02, -2.6150e-02,\n",
      "        -9.4091e-03, -2.0554e-02, -2.2026e-02, -1.1941e-02, -3.5366e-02,\n",
      "         8.1865e-03,  4.3265e-03,  4.5786e-03, -2.7238e-02, -4.4168e-03,\n",
      "         1.5356e-02, -7.0975e-04, -1.3183e-02, -9.6383e-03, -8.3668e-03,\n",
      "         3.5162e-02, -2.0826e-02,  7.6023e-03,  1.6346e-03,  7.7792e-04,\n",
      "         3.5542e-03, -1.9732e-02, -6.1363e-03,  3.0235e-02, -6.7652e-03,\n",
      "        -2.9653e-02, -1.3170e-02, -1.2419e-02, -2.2399e-02, -1.8686e-03,\n",
      "         1.2886e-02,  1.5595e-02,  3.4799e-02, -1.7794e-02, -2.4390e-02,\n",
      "         3.2030e-02, -2.1928e-02,  9.7759e-03,  1.8899e-02, -2.3565e-02,\n",
      "        -2.0631e-03,  2.7652e-02,  1.3516e-02,  1.2899e-02,  3.5196e-02,\n",
      "         1.4205e-02, -2.0759e-02, -2.5092e-02, -9.7068e-03, -3.0529e-02,\n",
      "        -3.5120e-02, -1.3963e-02,  1.2918e-02,  2.3360e-02, -3.5468e-02,\n",
      "        -2.2031e-03, -1.0814e-02,  9.0353e-05,  1.1032e-03,  1.5151e-02,\n",
      "         3.4589e-02,  3.0902e-02,  2.0528e-02, -2.4339e-02, -4.6612e-03,\n",
      "        -3.8716e-03, -1.0875e-02,  7.9081e-03, -2.7882e-02,  6.7455e-03,\n",
      "         8.4227e-03, -1.2492e-02, -1.0558e-02, -3.3997e-02,  2.8112e-02,\n",
      "        -9.1456e-03, -2.1471e-02, -2.0093e-02, -2.8615e-02,  1.3461e-03,\n",
      "        -1.8130e-02, -2.6795e-02,  1.4385e-02,  1.5173e-02,  2.9924e-02,\n",
      "         2.3714e-02,  1.0301e-02, -6.7519e-03,  4.1511e-05, -6.4909e-03,\n",
      "        -1.2365e-02, -1.4227e-02, -3.5109e-02, -1.3537e-02,  9.3652e-03,\n",
      "        -2.7443e-02,  2.0508e-02, -1.8103e-02,  1.5404e-02,  2.0164e-02,\n",
      "         3.4984e-02,  2.9638e-02, -3.0222e-02,  2.8640e-02, -4.6895e-03,\n",
      "         1.9756e-02,  2.3376e-03,  2.8940e-02,  2.0657e-02, -2.9611e-02,\n",
      "        -6.4576e-03, -7.9640e-03,  3.2679e-02, -3.4032e-02,  5.5525e-03,\n",
      "         2.1087e-02,  2.1663e-02, -2.5618e-02, -1.8202e-02, -3.6392e-03,\n",
      "         2.2728e-02, -1.6287e-02, -1.1628e-02, -1.5873e-02,  3.1809e-02,\n",
      "        -3.5335e-02,  6.5428e-03, -1.2526e-02,  1.5707e-02,  1.6273e-03,\n",
      "         2.9059e-02, -2.6016e-02,  3.0809e-02,  1.9434e-02, -7.0194e-03,\n",
      "         4.5650e-03, -2.9124e-02, -4.6067e-03,  5.4123e-03, -8.8832e-03,\n",
      "         3.0340e-02,  1.2963e-02, -8.3752e-03,  1.3710e-02,  3.4965e-03,\n",
      "        -3.3934e-02, -3.1407e-02,  2.1471e-02,  5.4497e-03,  8.3927e-03,\n",
      "         1.8393e-02, -1.2358e-02,  1.6935e-02, -1.7910e-02,  1.9344e-02,\n",
      "        -6.0694e-03,  2.3019e-02,  2.5157e-02,  8.5066e-03,  2.8121e-02,\n",
      "         1.6624e-02,  1.9487e-03, -3.2719e-02, -3.3819e-02, -1.4122e-02,\n",
      "        -2.5526e-02,  1.7084e-02, -1.8833e-02, -1.9069e-02, -2.0316e-02,\n",
      "        -9.5115e-03,  2.2251e-02,  2.4349e-02, -4.6306e-03, -1.0107e-03,\n",
      "         1.6634e-02, -3.3758e-02,  3.0644e-03,  4.0250e-03,  1.0046e-02,\n",
      "        -3.3728e-02,  1.0302e-02, -2.0234e-02, -3.2289e-02, -8.2615e-03,\n",
      "        -8.2597e-03,  1.2560e-02, -2.2729e-02,  1.9006e-02, -1.3016e-02,\n",
      "         8.4233e-03, -2.5944e-02,  8.7295e-03,  2.5830e-02,  1.5494e-02,\n",
      "        -1.6561e-02,  3.0329e-02,  6.2253e-03, -5.7548e-04, -2.4049e-02,\n",
      "        -2.1962e-04, -2.3219e-02,  2.0620e-02,  2.2062e-02,  2.5070e-02,\n",
      "         3.2272e-02, -1.3894e-02, -1.1679e-02,  1.3007e-02, -1.2543e-03,\n",
      "         1.1592e-02,  2.8686e-02, -8.5486e-03, -1.0274e-02, -9.9683e-03,\n",
      "         6.8199e-03,  1.1930e-02,  1.3522e-02,  2.2273e-02,  1.7357e-02,\n",
      "        -2.9572e-02,  5.5026e-03, -7.7768e-03,  4.7296e-03,  1.3861e-02,\n",
      "         2.2079e-02,  1.2379e-02, -1.4298e-02,  1.6057e-03,  6.1632e-03,\n",
      "         9.2045e-03, -6.5708e-04, -4.6921e-03, -9.0022e-03, -2.0894e-02,\n",
      "         7.9553e-03, -1.2675e-02,  3.2351e-02,  3.5651e-02, -5.2715e-04,\n",
      "         3.5571e-02,  7.0408e-03, -2.5910e-02, -1.6339e-02, -2.2954e-02,\n",
      "        -3.4320e-02, -2.6978e-02, -1.3730e-02, -2.6266e-02, -3.4641e-02,\n",
      "        -1.1120e-02,  1.9423e-02, -2.4315e-02, -2.5011e-02, -2.9542e-02,\n",
      "        -2.5822e-02,  3.2366e-02], device='cuda:0', requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "print(f\"First Linear weights: {model.linear_relu_stack[0].weight} \\n\")\n",
    "\n",
    "print(f\"First Linear bias: {model.linear_relu_stack[0].bias} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:32:54.657008500Z",
     "start_time": "2023-06-08T06:32:54.610025300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To use the model, we pass it the input data. This executes the model's forward, along with some background operations. However, do not call model.forward() directly! Calling the model on the input returns a 10-dimensional tensor with raw predicted values for each class.\n",
    "\n",
    "We get the prediction densities by passing it through an instance of the nn.Softmax."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([6], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:32:20.544412300Z",
     "start_time": "2023-06-08T06:32:17.010423300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "以下举例说明上述模型中的 layer，以 3 张 28*28 的图片为例。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:35:20.111301300Z",
     "start_time": "2023-06-08T06:35:20.026084800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# Flatten 会将 2D 的 28*28 的图片转换为 1D 的 784 的向量\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:35:51.429548700Z",
     "start_time": "2023-06-08T06:35:51.425490500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# Linear 会使用其存储的 weight 和 bias 对输入的 784 的向量做线性变换，转换为 20 的向量\n",
    "layer1 = nn.Linear(in_features=28 * 28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:57:41.460422Z",
     "start_time": "2023-06-08T06:57:41.450292300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2866,  0.0505, -0.0978,  0.1137,  0.3252, -0.3445, -0.5225, -0.1804,\n",
      "          0.0451, -0.4283,  0.2847,  0.1886,  0.1066,  0.8289,  0.1577, -0.3942,\n",
      "         -0.1343, -0.2590,  0.5462,  0.2448],\n",
      "        [ 0.1187, -0.0324, -0.1250,  0.3004,  0.3058, -0.3972, -0.3747,  0.1747,\n",
      "          0.1251, -0.4282,  0.4507,  0.3431,  0.0023,  0.6037,  0.6050, -0.1815,\n",
      "         -0.0409, -0.3206,  0.0945,  0.2545],\n",
      "        [ 0.2922,  0.0636, -0.2587,  0.2318,  0.0198, -0.1845, -0.2926,  0.0074,\n",
      "          0.3746, -0.4456,  0.3713,  0.3546, -0.1526,  0.5471,  0.4274, -0.1127,\n",
      "         -0.2227, -0.4861, -0.0498, -0.1933]], grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.2866, 0.0505, 0.0000, 0.1137, 0.3252, 0.0000, 0.0000, 0.0000, 0.0451,\n",
      "         0.0000, 0.2847, 0.1886, 0.1066, 0.8289, 0.1577, 0.0000, 0.0000, 0.0000,\n",
      "         0.5462, 0.2448],\n",
      "        [0.1187, 0.0000, 0.0000, 0.3004, 0.3058, 0.0000, 0.0000, 0.1747, 0.1251,\n",
      "         0.0000, 0.4507, 0.3431, 0.0023, 0.6037, 0.6050, 0.0000, 0.0000, 0.0000,\n",
      "         0.0945, 0.2545],\n",
      "        [0.2922, 0.0636, 0.0000, 0.2318, 0.0198, 0.0000, 0.0000, 0.0074, 0.3746,\n",
      "         0.0000, 0.3713, 0.3546, 0.0000, 0.5471, 0.4274, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ReLU 会对输入的 20 的向量做非线性变换，目的是为帮助神经网络学习各种各样的现象\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T06:59:00.760101600Z",
     "start_time": "2023-06-08T06:59:00.689850Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1799,  0.0852, -0.3402, -0.2800,  0.0255,  0.3052, -0.1402,  0.0298,\n",
      "         -0.0684,  0.1986],\n",
      "        [ 0.2339,  0.0604, -0.1770, -0.2691, -0.0673,  0.1105, -0.0235,  0.2472,\n",
      "         -0.2349,  0.2803],\n",
      "        [ 0.0760, -0.0758, -0.2676, -0.2299,  0.1419,  0.2491, -0.2389,  0.0145,\n",
      "         -0.0516,  0.2138]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Sequential 会将上述的操作组合起来，按照顺序执行\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "print(logits)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T07:00:37.351863700Z",
     "start_time": "2023-06-08T07:00:37.295817900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1175, 0.1069, 0.0698, 0.0742, 0.1007, 0.1332, 0.0853, 0.1011, 0.0917,\n",
      "         0.1197],\n",
      "        [0.1221, 0.1026, 0.0809, 0.0738, 0.0903, 0.1079, 0.0944, 0.1237, 0.0764,\n",
      "         0.1279],\n",
      "        [0.1080, 0.0928, 0.0766, 0.0795, 0.1153, 0.1284, 0.0788, 0.1015, 0.0951,\n",
      "         0.1239]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Softmax 会将 logits 转换为预测概率\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n",
    "print(pred_probab)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T07:01:17.996900200Z",
     "start_time": "2023-06-08T07:01:17.929847400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0064,  0.0033, -0.0008,  ..., -0.0349,  0.0304, -0.0191],\n",
      "        [ 0.0205,  0.0003,  0.0353,  ..., -0.0287, -0.0056,  0.0316]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0337, 0.0332], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0002,  0.0346, -0.0395,  ..., -0.0198, -0.0107,  0.0116],\n",
      "        [-0.0117, -0.0299, -0.0269,  ..., -0.0088,  0.0311,  0.0043]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0346,  0.0086], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0231,  0.0163, -0.0388,  ...,  0.0133, -0.0188, -0.0100],\n",
      "        [-0.0249, -0.0330,  0.0254,  ..., -0.0417,  0.0361,  0.0322]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0396, -0.0355], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 模型参数，比如 weights 和 bias 会在训练是进行优化\n",
    "# 通过 model.parameters() 可以获取模型中的所有参数\n",
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-08T07:06:51.878223800Z",
     "start_time": "2023-06-08T07:06:51.859164700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
